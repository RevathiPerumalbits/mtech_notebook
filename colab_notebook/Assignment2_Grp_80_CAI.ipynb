{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPUXBT6sH3r9xapeJf5CIWf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install pytesseract\n","%pip install PyMuPDF\n","%pip install pdf2image\n","%pip install pandas\n","%pip install pdfplumber"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GA6GE_WG9eNr","executionInfo":{"status":"ok","timestamp":1754768528098,"user_tz":-330,"elapsed":24750,"user":{"displayName":"REVATHI P","userId":"07797098857097259305"}},"outputId":"30ee81e5-ee9d-4f25-8aef-be73100f6f6d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.3.0)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.13\n","Collecting PyMuPDF\n","  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n","Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDF\n","Successfully installed PyMuPDF-1.26.3\n","Collecting pdf2image\n","  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image) (11.3.0)\n","Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n","Installing collected packages: pdf2image\n","Successfully installed pdf2image-1.17.0\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n","  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n","Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-r98hon4kAI","executionInfo":{"status":"ok","timestamp":1754749381995,"user_tz":-330,"elapsed":154468,"user":{"displayName":"REVATHI P","userId":"07797098857097259305"}},"outputId":"c7f43237-ed65-427a-a0e7-0990990ed0e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","Processing Infosys 2023 filing...\n","Converting to text and extracting tables...\n","Cleaning text...\n","Segmenting report...\n","\n","=== 2023 Income Statement ===\n","Text: Income tax expense in the consolidated statement of comprehensive income comprises: (Dollars in millions) Year ended March 31, 2023 2022 2021 Current taxes Domestic taxes 830 785 716 Foreign taxes 323 263 185 1,153 1,048 901 Deferred taxes Domestic taxes 54 48 85 Foreign taxes (65) (28) (13) (11) 20 72 Income tax expense 1,142 1,068 973 Income tax expense for fiscal 2023, 2022 and 2021 includes reversals (net of provisions) of $13 million, $36 million and $47 million, respectively. These reversa...\n","Tables: 2 tables found.\n","\n","=== 2023 Balance Sheet ===\n","Text: (1) Financial Services include enterprises in Financial Services and Insurance (2) Retail includes enterprises in Retail, Consumer Packaged Goods and Logistics (3) Communication includes enterprises in Communication, Telecom OEM and Media (4) Life Sciences includes enterprises in Life sciences and Health care (5) Others include operating segments of businesses in India, Japan, China, Infosys Public Services & other enterprises in Public Services * Geographical revenues are based on the domicile ...\n","Tables: 0 tables found.\n","\n","Processing Infosys 2024 filing...\n","Converting to text and extracting tables...\n","Cleaning text...\n","Segmenting report...\n","\n","=== 2024 Income Statement ===\n","Text: Income tax expense in the consolidated statement of comprehensive income comprises: (Dollars in millions) Year ended March 31, 2024 2023 2022 Current taxes Domestic taxes 768 830 785 Foreign taxes 247 323 263 1,015 1,153 1,048 Deferred taxes Domestic taxes 180 54 48 Foreign taxes (18 ) (65 ) (28) 162 (11 ) 20 Income tax expense 1,177 1,142 1,068 Income tax expense for fiscal 2024, 2023 and 2022 includes reversals (net of provisions) of $113 million, $13 million and $36 million, respectively. The...\n","Tables: 0 tables found.\n","\n","=== 2024 Balance Sheet ===\n","Text: Disaggregated revenue information Revenue disaggregation by business segments has been included in segment information (Refer to note 2.21). The table below presents disaggregated revenues from contracts with customers by geography and contract type. The Group believes this disaggregation best depicts how the nature, amount, timing and uncertainty of revenues and cash flows are affected by industry, market and other economic factors. Year ended March 31, 2024, March 31, 2023 and March 31, 2022 (...\n","Tables: 0 tables found.\n"]}],"source":["import requests\n","import pdfplumber\n","from bs4 import BeautifulSoup\n","import re\n","import os\n","from io import StringIO\n","from google.colab import drive\n","import os\n","\n","import logging\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the base folder where your PDFs are stored in Google Drive\n","base_folder = \"/content/drive/MyDrive/output\"\n","drive_folder = \"/content/drive/MyDrive/output\"\n","# Step 2: Convert PDF or HTML to text and extract tables\n","def convert_to_text_and_tables(file_path, file_type):\n","    logger.info(f\"Converting {file_type} to text and extracting tables from {file_path}\")\n","    text = \"\"\n","    tables = []\n","    page_texts = []\n","    if file_type == \"pdf\":\n","        try:\n","            with pdfplumber.open(file_path) as pdf:\n","                for page_num, page in enumerate(pdf.pages, 1):\n","                    # Extract text\n","                    extracted_text = page.extract_text()\n","                    if extracted_text:\n","                        text += f\"\\n[Page {page_num}]\\n{extracted_text}\\n\"\n","                        page_texts.append((page_num, extracted_text))\n","                    else:\n","                        page_texts.append((page_num, \"\"))\n","                    # Extract tables with improved settings\n","                    page_tables = page.extract_tables(table_settings={\n","                        \"vertical_strategy\": \"lines_strict\",\n","                        \"horizontal_strategy\": \"lines_strict\",\n","                        \"snap_tolerance\": 3\n","                    })\n","                    for table in page_tables:\n","                        if table and any(row for row in table if any(cell for cell in row)):  # Ensure table is not empty\n","                            tables.append((page_num, table))\n","        except Exception as e:\n","            logger.error(f\"PDF extraction failed: {e}\")\n","    elif file_type == \"html\":\n","        try:\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                soup = BeautifulSoup(f, 'html.parser')\n","                text = soup.get_text(separator=' ', strip=True)\n","                page_texts.append((1, text))\n","                # Extract HTML tables\n","                html_tables = soup.find_all('table')\n","                for i, html_table in enumerate(html_tables, 1):\n","                    table_data = []\n","                    for row in html_table.find_all('tr'):\n","                        row_data = [cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])]\n","                        if row_data:\n","                            table_data.append(row_data)\n","                    if table_data:\n","                        tables.append((i, table_data))\n","        except Exception as e:\n","            logger.error(f\"HTML extraction failed: {e}\")\n","\n","    else:\n","        logger.error(f\"Unsupported file type: {file_type}\")\n","    return text, tables, page_texts\n","\n","# Step 3: Clean text and table data\n","def clean_text(text):\n","    logger.info(\"Cleaning text...\")\n","    # Remove page numbers\n","    text = re.sub(r'Page \\d+ of \\d+', '', text)\n","    # Remove Infosys-specific headers\n","    text = re.sub(r'Infosys Limited\\s+\\d{4}\\s+Form 20-F', '', text, flags=re.IGNORECASE)\n","    text = re.sub(r'Infosys Integrated Annual Report \\d{4}-\\d{2}', '', text, flags=re.IGNORECASE)\n","    # Remove boilerplate text\n","    text = re.sub(r'This document contains forward-looking statements.*?(?=\\.)', '', text, flags=re.DOTALL)\n","    text = re.sub(r'Pursuant to the requirements of the Securities Exchange Act.*?(?=\\.)', '', text, flags=re.DOTALL)\n","    # Remove extra whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    logger.info(\"Text cleaned successfully\")\n","    return text\n","\n","def clean_table(table):\n","    logger.info(\"Cleaning table data...\")\n","    if not table:\n","        return []\n","    # Handle None values in cells and normalize\n","    cleaned_table = []\n","    for row in table:\n","        cleaned_row = [str(cell).strip() if cell is not None else '' for cell in row]\n","        if any(cell for cell in cleaned_row):  # Skip entirely empty rows\n","            cleaned_table.append(cleaned_row)\n","\n","    # Remove common table noise\n","    try:\n","        cleaned_table = [\n","            row for row in cleaned_table\n","            if not re.match(r'(?i)(in millions|note \\d+|see accompanying notes|total assets|total liabilities)', ' '.join(row))\n","        ]\n","    except Exception as e:\n","        print(f\"Error cleaning table: {e}\")\n","        return []\n","    logger.info(\"Table cleaned successfully\")\n","    return cleaned_table\n","\n","# Step 4: Convert table to text format\n","def table_to_text(table):\n","    logger.info(\"Converting table to text format...\")\n","    if not table:\n","        return \"\"\n","    output = StringIO()\n","    for row in table:\n","        cleaned_row = [cell if cell else '' for cell in row]\n","        output.write('\\t'.join(cleaned_row) + '\\n')\n","    logger.info(\"Table converted to text format successfully\")\n","    return output.getvalue()\n","\n","\n","# Step 5: Segment text and associate tables with sections\n","def segment_report(text, tables, page_texts):\n","    sections = {\n","        \"income_statement\": {\"text\": \"\", \"tables\": []},\n","        \"balance_sheet\": {\"text\": \"\", \"tables\": []}\n","    }\n","\n","    # Enhanced regex patterns\n","    patterns = {\n","        \"income_statement\": r'(?i)(Consolidated Statement of (Profit and Loss|Profit or Loss|Income|Comprehensive Income))\\b.*?(?=(Consolidated (Balance Sheet|Statement of (Cash Flows|Financial Position|Changes in Equity))|$))',\n","        \"balance_sheet\": r'(?i)(Consolidated Balance Sheet)\\b.*?(?=(Consolidated Statement of (Cash Flows|Changes in Equity)|$))',\n","        #\"cash_flow_statement\": r'(?i)(Consolidated Statement of Cash Flows)\\b.*?(?=(Consolidated Statement of|$))'\n","    }\n","\n","    current_section = None\n","    section_text = []\n","    section_start_page = 0\n","    used_tables = set()  # Track used table indices\n","\n","    # Segment text and associate tables\n","    for page_num, page_text in page_texts:\n","        page_text_clean = clean_text(page_text)\n","        for section, pattern in patterns.items():\n","            if re.search(pattern, page_text_clean, re.IGNORECASE):\n","                if current_section and section_text:\n","                    sections[current_section][\"text\"] = ' '.join(section_text).strip()\n","                    # Assign tables from section_start_page to current page\n","                    for table_page, table in tables:\n","                        if section_start_page <= table_page < page_num and table_page not in used_tables:\n","                            cleaned_table = clean_table(table)\n","                            if cleaned_table:\n","                                sections[current_section][\"tables\"].append(cleaned_table)\n","                                used_tables.add(table_page)\n","                current_section = section\n","                section_start_page = page_num\n","                section_text = [page_text_clean]\n","                break\n","        if current_section:\n","            section_text.append(page_text_clean)\n","\n","    # Add final section text and tables\n","    if current_section and section_text:\n","        sections[current_section][\"text\"] = ' '.join(section_text).strip()\n","        for table_page, table in tables:\n","            if table_page >= section_start_page and table_page not in used_tables:\n","                cleaned_table = clean_table(table)\n","                if cleaned_table:\n","                    sections[current_section][\"tables\"].append(cleaned_table)\n","                    used_tables.add(table_page)\n","\n","    # Log debug output if no sections found\n","    if not any(sections[section][\"text\"] or sections[section][\"tables\"] for section in sections):\n","        debug_file = f\"infosys_debug_{filing.get('year', 'unknown')}.txt\"\n","        print(f\"Warning: No sections or tables found. Saving all text and tables to {debug_file}.\")\n","        with open(debug_file, 'w', encoding='utf-8') as f:\n","            f.write(\"=== Debug Output ===\\n\\n\")\n","            f.write(\"All Text Content:\\n\")\n","            f.write(text + \"\\n\\n\")\n","            f.write(\"All Tables:\\n\")\n","            for table_page, table in tables:\n","                f.write(f\"Table on Page {table_page}:\\n\")\n","                f.write(table_to_text(clean_table(table)))\n","                f.write(\"\\n\")\n","\n","    return sections\n","\n","#Step 6: Save combined text and table data to text files\n","def save_section_to_text(section_name, section_data, output_file):\n","    with open(output_file, 'w', encoding='utf-8') as f:\n","        f.write(f\"=== {section_name.replace('_', ' ').title()} ===\\n\\n\")\n","        if section_data[\"text\"]:\n","            f.write(\"Text Content:\\n\")\n","            f.write(section_data[\"text\"] + \"\\n\\n\")\n","        else:\n","            f.write(\"Text Content: Not found\\n\\n\")\n","\n","        f.write(\"Table Content:\\n\")\n","        if section_data[\"tables\"]:\n","            for i, table in enumerate(section_data[\"tables\"], 1):\n","                f.write(f\"Table {i}:\\n\")\n","                f.write(table_to_text(table))\n","                f.write(\"\\n\")\n","        else:\n","            f.write(\"No tables found.\\n\")\n","\n","# Main execution\n","def main():\n","    global filing\n","    # Define filings for Infosys 2023 and 2024\n","    filings = [\n","\n","        {\n","            \"year\": 2023,\n","            \"url\": \"infosys_2023.pdf\",  # Local file from provided document\n","            \"file_path\": os.path.join(base_folder, \"infosys_2023.pdf\"),\n","            \"file_type\": \"pdf\"\n","        },\n","        {\n","            \"year\": 2024,\n","            \"url\": \"infosys_2024.pdf\",  # Local file from provided document\n","            \"file_path\": os.path.join(base_folder, \"infosys_2024.pdf\"),\n","            \"file_type\": \"pdf\"\n","        },\n","\n","    ]\n","\n","    for filing in filings:\n","        print(f\"\\nProcessing Infosys {filing['year']} filing...\")\n","\n","        # Check if file exists locally\n","        file_path = filing['file_path']\n","\n","\n","        # Convert to text and extract tables\n","        print(\"Converting to text and extracting tables...\")\n","        raw_text, tables, page_texts = convert_to_text_and_tables(file_path, filing['file_type'])\n","        if not raw_text and not tables:\n","            print(f\"No text or tables extracted for {filing['year']}.\")\n","            continue\n","\n","        # Clean text\n","        print(\"Cleaning text...\")\n","        cleaned_text = clean_text(raw_text)\n","\n","        # Segment report\n","        print(\"Segmenting report...\")\n","        sections = segment_report(cleaned_text, tables, page_texts)\n","\n","        # Output results and save to files\n","        for section, content in sections.items():\n","            print(f\"\\n=== {filing['year']} {section.replace('_', ' ').title()} ===\")\n","            print(\"Text:\", content[\"text\"][:500] + \"...\" if content[\"text\"] else \"Section text not found.\")\n","            print(\"Tables:\", len(content[\"tables\"]), \"tables found.\")\n","\n","            # Save combined text and table data to a single text file\n","            output_file = os.path.join(drive_folder, f\"infosys_{filing['year']}_{section}.txt\")\n","            save_section_to_text(section, content, output_file)\n","\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Construct at least 50 question-answer (Q/A) pairs reflecting the financial data.\n","Example:\n","Q: What was the company’s revenue in 2023?\n","A: The company’s revenue in 2023 was $4.13 billion."],"metadata":{"id":"yxyAHaTxDe-h"}},{"cell_type":"code","source":["import os\n","import re\n","\n","def extract_financial_data_from_text(text):\n","    \"\"\"Extracts key financial data points from the text using regex patterns.\"\"\"\n","    data = {}\n","\n","    # Example patterns for text (these will need to be refined based on actual report structure)\n","    # Look for revenue\n","    revenue_match = re.search(r'(?i)revenue\\s+.*?(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s+million', text)\n","    if revenue_match:\n","        data['Revenue'] = revenue_match.group(1) + \" million\"\n","\n","    # Look for net income/profit\n","    net_income_match = re.search(r'(?i)(?:net income|profit)\\s+.*?(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s+million', text)\n","    if net_income_match:\n","        data['Net Income'] = net_income_match.group(1) + \" million\"\n","\n","    # Look for total assets\n","    assets_match = re.search(r'(?i)total assets\\s+.*?(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s+million', text)\n","    if assets_match:\n","        data['Total Assets'] = assets_match.group(1) + \" million\"\n","\n","    # Look for total liabilities\n","    liabilities_match = re.search(r'(?i)total liabilities\\s+.*?(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s+million', text)\n","    if liabilities_match:\n","        data['Total Liabilities'] = liabilities_match.group(1) + \" million\"\n","\n","    # Look for cash and cash equivalents\n","    cash_match = re.search(r'(?i)cash and cash equivalents\\s+.*?(\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s+million', text)\n","    if cash_match:\n","        data['Cash and Cash Equivalents'] = cash_match.group(1) + \" million\"\n","\n","\n","    return data\n","\n","def extract_financial_data_from_tables(tables, section_name, year):\n","    \"\"\"Extracts financial data points from tables with improved logic.\"\"\"\n","    data = {}\n","    for table in tables:\n","        if not table:\n","            continue\n","        try:\n","            header = []\n","            rows = []\n","            # Assuming the first row is the header\n","            if table and table[0]:\n","                header = [cell.strip() if cell else '' for cell in table[0]]\n","                rows = table[1:]\n","\n","            # Find the column index for the specified year\n","            year_col_index = -1\n","            for i, col_header in enumerate(header):\n","                if str(year) in col_header:\n","                    year_col_index = i\n","                    break\n","\n","            if year_col_index != -1:\n","                for row in rows:\n","                    if row and len(row) > year_col_index:\n","                        key = row[0].strip() if row[0] else ''\n","                        value = row[year_col_index].strip() if len(row) > year_col_index and row[year_col_index] else ''\n","\n","                        if key and value and not re.search(r'(?i)(in millions|note \\d+|see accompanying notes|total assets|total liabilities)', key):\n","                             # Clean and format the key\n","                            cleaned_key = re.sub(r'\\(.*?\\)', '', key).strip() # Remove anything in parentheses\n","                            cleaned_key = re.sub(r'\\[.*?\\]', '', cleaned_key).strip() # Remove anything in brackets\n","                            cleaned_key = re.sub(r'\\,', '', cleaned_key).strip() # Remove commas\n","\n","                            # Add the key-value pair if the value is not empty\n","                            if cleaned_key and value:\n","                                data[cleaned_key] = value\n","\n","        except Exception as e:\n","            print(f\"Error processing table: {e}\")\n","            continue\n","    return data\n","\n","\n","def generate_qa_pairs(financial_data, year, section_name):\n","    \"\"\"Generates Q/A pairs from extracted financial data.\"\"\"\n","    qa_pairs = []\n","    for key, value in financial_data.items():\n","        # Avoid generating generic questions for keys without meaningful values\n","        if value and value.strip():\n","            question = f\"According to the {section_name.replace('_', ' ')}, what was the {key.lower()} in {year}?\"\n","            answer = f\"The {key.lower()} in {year} was {value}.\"\n","            qa_pairs.append({\"Q\": question, \"A\": answer})\n","    return qa_pairs\n","\n","# Define the folder where the processed text files are saved\n","processed_data_folder = \"/content/drive/MyDrive/output\" # Assuming saved in the same folder as the original PDF\n","\n","all_qa_pairs = []\n","\n","for filing_year in [2023,2024]: # Process for the year 2023\n","    for section in [\"income_statement\", \"balance_sheet\"]:\n","        file_name = f\"infosys_{filing_year}_{section}.txt\"\n","        file_path = os.path.join(processed_data_folder, file_name)\n","\n","        if os.path.exists(file_path):\n","            with open(file_path, 'r', encoding='utf-8') as f:\n","                content = f.read()\n","\n","            # Extract text content from the file\n","            text_content_match = re.search(r'Text Content:\\n(.*?)\\n\\nTable Content:', content, re.DOTALL)\n","            text_content = text_content_match.group(1).strip() if text_content_match else \"\"\n","\n","            # Extract table content from the file\n","            table_content_match = re.search(r'Table Content:\\n(.*)', content, re.DOTALL)\n","            table_content = table_content_match.group(1).strip() if table_content_match else \"\"\n","\n","            # Parse table content (simple parsing assuming tab-separated values)\n","            tables_from_file = []\n","            current_table = []\n","            if table_content:\n","                for line in table_content.split('\\n'):\n","                    if line.startswith('Table'):\n","                        if current_table:\n","                            tables_from_file.append(current_table)\n","                        current_table = []\n","                    elif line.strip(): # Avoid adding empty lines\n","                         current_table.append(line.split('\\t'))\n","                if current_table:\n","                    tables_from_file.append(current_table)\n","\n","            # Extract financial data from the text\n","            financial_data_from_text = extract_financial_data_from_text(text_content)\n","            qa_pairs_from_text = generate_qa_pairs(financial_data_from_text, filing_year, section)\n","            all_qa_pairs.extend(qa_pairs_from_text)\n","\n","            # Extract financial data from tables\n","            financial_data_from_tables = extract_financial_data_from_tables(tables_from_file, section, filing_year)\n","            qa_pairs_from_tables = generate_qa_pairs(financial_data_from_tables, filing_year, section)\n","            all_qa_pairs.extend(qa_pairs_from_tables)\n","\n","\n","# Print the generated Q/A pairs\n","print(f\"Generated {len(all_qa_pairs)} Q/A pairs:\")\n","for i, qa in enumerate(all_qa_pairs):\n","    print(f\"{i+1}. Q: {qa['Q']}\")\n","    print(f\"   A: {qa['A']}\")\n","\n","# You can further process or save the all_qa_pairs list as needed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrvFNJTWDelN","executionInfo":{"status":"ok","timestamp":1754750083945,"user_tz":-330,"elapsed":159,"user":{"displayName":"REVATHI P","userId":"07797098857097259305"}},"outputId":"8a97c2b2-787a-4db3-f03d-3c0135273b7c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated 6 Q/A pairs:\n","1. Q: According to the income statement, what was the revenue in 2023?\n","   A: The revenue in 2023 was $846 million.\n","2. Q: According to the income statement, what was the net income in 2023?\n","   A: The net income in 2023 was $13 million.\n","3. Q: According to the balance sheet, what was the revenue in 2023?\n","   A: The revenue in 2023 was $669 million.\n","4. Q: According to the income statement, what was the revenue in 2024?\n","   A: The revenue in 2024 was $940 million.\n","5. Q: According to the income statement, what was the net income in 2024?\n","   A: The net income in 2024 was $196 million.\n","6. Q: According to the balance sheet, what was the revenue in 2024?\n","   A: The revenue in 2024 was $656 million.\n"]}]},{"cell_type":"markdown","source":["New Code"],"metadata":{"id":"wS0UmRFLUj3C"}},{"cell_type":"code","source":["import pdfplumber\n","import re\n","import os\n","from io import StringIO\n","import logging\n","from google.colab import drive\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the base folder where your PDFs are stored in Google Drive\n","base_folder = \"/content/drive/MyDrive/output\"\n","qa_folder = \"/content/drive/MyDrive/qa\"\n","# Define regex patterns\n","note_pattern = r'(\\d+\\.\\d+(?:,\\s*\\d+\\.\\d+)*\\s*(?:and\\s*\\d+\\.\\d+)?)?'  # Matches 2.1, 2.12, 2.6, 2.7 and 2.18\n","number_pattern = r'-?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?|\\(\\d{1,3}(?:,\\d{3})*\\)|\\d+\\s+\\d+'  # Matches 2,861, -4,579, (2), or \"2 305\"\n","item_pattern = r'^(.*?)(?:\\s+(' + note_pattern + r'))?\\s*(' + number_pattern + r')?\\s*(' + number_pattern + r')?\\s*$'  # Flexible matching\n","header_pattern_balance = r'Consolidated Balance Sheet as of March 31'  # Identifies the balance sheet section\n","header_pattern_income = r'Consolidated Statements of Comprehensive Income for the years ended March 31'  # Identifies the income statement section\n","\n","# Initialize debug log\n","debug_log = []\n","\n","def process_line(line):\n","    \"\"\"Process a single line using regex to extract item, note, and values.\"\"\"\n","    line = line.strip()\n","    if not line:\n","        return None\n","    # Check if line is a section header (e.g., ASSETS, Current assets, Revenues)\n","    if line.isupper() or any(keyword in line.lower() for keyword in [\"assets\", \"liabilities\", \"equity\", \"investments\", \"capital\", \"revenues\", \"expenses\", \"income\",\"profit\",\"loss\",\"earnings\",\"baisc\",\"tax\",\"net\"\"current\"]):\n","        return f\"\\n{line}\"\n","    # Try to match line items with regex\n","    try:\n","        match = re.match(item_pattern, line, re.IGNORECASE)\n","        if match:\n","            groups = match.groups()\n","            if len(groups) > 4:\n","                debug_log.append(f\"Too many groups in line: '{line}' -> {groups}\")\n","                return None\n","            item, note, val_2024, val_2023 = (groups + (None, None, None, None))[:4]  # Pad with None\n","            item = item.strip() if item else \"\"\n","            note = note if note else \"\"\n","            val_2024 = val_2024 if val_2024 else \"\"\n","            val_2023 = val_2023 if val_2023 else \"\"\n","            if item and (val_2024 or val_2023 or note):\n","                return f\"{item}\\t{note}\\t{val_2024}\\t{val_2023}\"\n","            else:\n","                debug_log.append(f\"Skipped line (no meaningful data): '{line}'\")\n","        else:\n","            debug_log.append(f\"No match for line: '{line}'\")\n","    except Exception as e:\n","        debug_log.append(f\"Error processing line '{line}': {str(e)}\")\n","    return None\n","\n","def convert_to_text_and_tables(file_path, file_type):\n","    logger.info(f\"Converting {file_type} to text and extracting tables from {file_path}\")\n","    text = \"\"\n","    tables = []\n","    page_texts = []\n","    balance_sheet_lines = [\"Consolidated Balance Sheet as of March 31 (Dollars in millions except equity share data)\"]\n","    balance_sheet_lines.append(\"Item\\tNote\\t2024\\t2023\")\n","    income_statement_lines = [\"Consolidated Statements of Comprehensive Income for the years ended March 31\"]\n","    income_statement_lines.append(\"Item\\tNote\\t2024\\t2023\")\n","\n","    if file_type == \"pdf\":\n","        try:\n","            with pdfplumber.open(file_path) as pdf:\n","                found_balance_sheet = False\n","                found_income_statement = False\n","                for page_num, page in enumerate(pdf.pages, 1):\n","                    # Extract text with layout=True to preserve formatting\n","                    extracted_text = page.extract_text(layout=True)\n","                    if extracted_text:\n","                        text += f\"\\n[Page {page_num}]\\n{extracted_text}\\n\"\n","                        page_texts.append((page_num, extracted_text))\n","                        # Process text for balance sheet or income statement if header is found\n","                        if re.search(header_pattern_balance, extracted_text, re.IGNORECASE):\n","                            found_balance_sheet = True\n","                            for line in extracted_text.splitlines():\n","                                processed = process_line(line)\n","                                if processed:\n","                                    balance_sheet_lines.append(processed)\n","                        elif re.search(header_pattern_income, extracted_text, re.IGNORECASE):\n","                            found_income_statement = True\n","                            for line in extracted_text.splitlines():\n","                                processed = process_line(line)\n","                                if processed:\n","                                    income_statement_lines.append(processed)\n","                    else:\n","                        page_texts.append((page_num, \"\"))\n","\n","                    # Extract tables as fallback\n","                    page_tables = page.extract_tables(table_settings={\n","                        \"vertical_strategy\": \"lines_strict\",\n","                        \"horizontal_strategy\": \"lines_strict\",\n","                        \"snap_tolerance\": 3,\n","                        \"join_tolerance\": 3\n","                    })\n","                    for table in page_tables:\n","                        if table and any(row for row in table if any(cell for cell in row if cell)):\n","                            tables.append((page_num, table))\n","                            logger.info(f\"Extracted table on page {page_num}\")\n","                            # Process table rows for balance sheet or income statement if header was found\n","                            if found_balance_sheet:\n","                                for row in table:\n","                                    row_text = \" \".join(str(cell) for cell in row if cell)\n","                                    processed = process_line(row_text)\n","                                    if processed:\n","                                        balance_sheet_lines.append(processed)\n","                            elif found_income_statement:\n","                                for row in table:\n","                                    row_text = \" \".join(str(cell) for cell in row if cell)\n","                                    processed = process_line(row_text)\n","                                    if processed:\n","                                        income_statement_lines.append(processed)\n","\n","                if not found_balance_sheet:\n","                    logger.warning(\"Consolidated Balance Sheet not found in the PDF\")\n","                if not found_income_statement:\n","                    logger.warning(\"Consolidated Statements of Comprehensive Income not found in the PDF\")\n","        except Exception as e:\n","            logger.error(f\"PDF extraction failed: {e}\")\n","\n","    return text, tables, page_texts, balance_sheet_lines, income_statement_lines\n","\n","def clean_table(table):\n","    logger.info(\"Cleaning table data...\")\n","    if not table:\n","        return []\n","    cleaned_table = []\n","    for row in table:\n","        cleaned_row = [str(cell).strip() if cell is not None else '' for cell in row]\n","        if any(cell for cell in cleaned_row):\n","            # Process each row as a line to apply regex\n","            row_text = \" \".join(cleaned_row)\n","            processed = process_line(row_text)\n","            if processed:\n","                cleaned_table.append(processed.split(\"\\t\"))\n","    logger.info(\"Table cleaned successfully\")\n","    return cleaned_table\n","\n","def table_to_text(table):\n","    logger.info(\"Converting table to text format...\")\n","    if not table:\n","        return \"\"\n","    output = StringIO()\n","    for row in table:\n","        output.write('\\t'.join(str(cell) if cell else '' for cell in row) + '\\n')\n","    logger.info(\"Table converted to text format successfully\")\n","    return output.getvalue()\n","\n","def clean_text(text):\n","    logger.info(\"Cleaning text...\")\n","    text = re.sub(r'Page \\d+ of \\d+', '', text)\n","    text = re.sub(r'Infosys Limited\\s+\\d{4}\\s+Form 20-F', '', text, flags=re.IGNORECASE)\n","    text = re.sub(r'Infosys Integrated Annual Report \\d{4}-\\d{2}', '', text, flags=re.IGNORECASE)\n","    text = re.sub(r'This document contains forward-looking statements.*?(?=\\.)', '', text, flags=re.DOTALL)\n","    text = re.sub(r'Pursuant to the requirements of the Securities Exchange Act.*?(?=\\.)', '', text, flags=re.DOTALL)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    logger.info(\"Text cleaned successfully\")\n","    return text\n","\n","def segment_report(text, tables, page_texts, balance_sheet_lines, income_statement_lines):\n","    logger.info(\"Segmenting report...\")\n","    sections = {\n","        \"balance_sheet\": {\"text\": \"\", \"tables\": [], \"lines\": balance_sheet_lines},\n","        \"income_statement\": {\"text\": \"\", \"tables\": [], \"lines\": income_statement_lines}\n","    }\n","\n","    # Enhanced regex patterns\n","    patterns = {\n","        \"balance_sheet\": r'(?i)(Consolidated Balance Sheet as of March 31,)\\b.*?(?=(Consolidated Statement of (Cash Flows|Changes in Equity|Comprehensive Income)|$))',\n","        \"income_statement\": r'(?i)(Consolidated Statements of Comprehensive Income for the years ended March 31)\\b.*?(?=(Consolidated (Balance Sheet|Statement of (Cash Flows|Changes in Equity))|$))'\n","    }\n","\n","    current_section = None\n","    section_text = []\n","    section_start_page = 0\n","    used_tables = set()\n","\n","    for page_num, page_text in page_texts:\n","        if page_num < 50:  # Skip early pages\n","            continue\n","        page_text_clean = clean_text(page_text)\n","        for section, pattern in patterns.items():\n","            if re.search(pattern, page_text_clean, re.IGNORECASE):\n","                logger.info(f\"Found {section} on page {page_num}: {page_text_clean[:100]}...\")\n","                if current_section and section_text:\n","                    sections[current_section][\"text\"] = ' '.join(section_text).strip()\n","                    for table_page, table in tables:\n","                        if section_start_page <= table_page < page_num and table_page not in used_tables:\n","                            cleaned_table = clean_table(table)\n","                            if cleaned_table:\n","                                sections[current_section][\"tables\"].append(cleaned_table)\n","                                used_tables.add(table_page)\n","                                logger.info(f\"Assigned table on page {table_page} to {current_section}\")\n","                current_section = section\n","                section_start_page = page_num\n","                section_text = [page_text_clean]\n","                break\n","        if current_section:\n","            section_text.append(page_text_clean)\n","\n","    if current_section and section_text:\n","        sections[current_section][\"text\"] = ' '.join(section_text).strip()\n","        for table_page, table in tables:\n","            if table_page >= section_start_page and table_page not in used_tables:\n","                cleaned_table = clean_table(table)\n","                if cleaned_table:\n","                    sections[current_section][\"tables\"].append(cleaned_table)\n","                    used_tables.add(table_page)\n","                    logger.info(f\"Assigned table on page {table_page} to {current_section}\")\n","\n","    # Log debug output\n","    debug_file = os.path.join(base_folder, \"infosys_debug_2024.txt\")\n","    with open(debug_file, 'w', encoding='utf-8') as f:\n","        f.write(\"=== Debug Output ===\\n\\n\")\n","        f.write(\"Section Matches:\\n\")\n","        for section, content in sections.items():\n","            f.write(f\"{section}:\\n\")\n","            f.write(f\"Text: {content['text'][:500] + '...' if content['text'] else 'Not found'}\\n\")\n","            f.write(f\"Tables: {len(content['tables'])} found\\n\")\n","            f.write(\"Extracted Lines:\\n\")\n","            f.write('\\n'.join(content['lines']) + '\\n\\n')\n","        f.write(\"All Tables:\\n\")\n","        for table_page, table in tables:\n","            f.write(f\"Table on Page {table_page}:\\n\")\n","            f.write(table_to_text(clean_table(table)))\n","            f.write(\"\\n\")\n","        f.write(\"Debug Log:\\n\")\n","        for log_entry in debug_log:\n","            f.write(log_entry + \"\\n\")\n","\n","    logger.info(\"Report segmentation completed\")\n","    return sections\n","\n","def save_section_to_text(section_name, section_data, output_file, output_folder=\"output\"):\n","    logger.info(f\"Saving section {section_name} to {output_file} in folder {output_folder}\")\n","    # Ensure the output folder exists\n","    #os.makedirs(output_folder, exist_ok=True)\n","    # Construct the full file path\n","    full_output_path = os.path.join(base_folder, output_file)\n","\n","    with open(os.path.join(base_folder, output_file), 'w', encoding='utf-8') as f:\n","        f.write(f\"=== {section_name.replace('_', ' ').title()} ===\\n\\n\")\n","        f.write(\"Text Content:\\n\")\n","        f.write(section_data[\"text\"] + \"\\n\\n\" if section_data[\"text\"] else \"Text Content: Not found\\n\\n\")\n","        f.write(\"Table Content:\\n\")\n","        if section_data[\"lines\"]:\n","            f.write('\\n'.join(section_data[\"lines\"]) + \"\\n\")\n","        else:\n","            f.write(f\"No {section_name.replace('_', ' ')} lines extracted.\\n\")\n","    logger.info(f\"Saved section {section_name} successfully to {full_output_path}\")\n","\n","\n","def main():\n","    global filing\n","    filings = [\n","        {\n","            \"year\": 2024,\n","            \"url\": \"infosys_2024.pdf\",\n","            \"file_path\":  os.path.join(base_folder, \"infosys_2024.pdf\"),\n","            \"file_type\": \"pdf\"\n","        },\n","        {\n","            \"year\": 2023,\n","            \"url\": \"infosys_2023.pdf\",\n","            \"file_path\":  os.path.join(base_folder, \"infosys_2023.pdf\"),\n","            \"file_type\": \"pdf\"\n","        }\n","    ]\n","\n","    for filing in filings:\n","        logger.info(f\"Processing Infosys {filing['year']} filing...\")\n","\n","        file_path = filing['file_path']\n","        year = os.path.basename(file_path).split(\"_\")[1].split(\".\")[0]\n","        if not os.path.exists(file_path):\n","            logger.error(f\"File not found: {file_path}\")\n","            continue\n","\n","        # Convert to text and extract tables\n","        logger.info(\"Converting to text and extracting tables...\")\n","        raw_text, tables, page_texts, balance_sheet_lines, income_statement_lines = convert_to_text_and_tables(file_path, filing['file_type'])\n","        if not raw_text and not tables and not balance_sheet_lines and not income_statement_lines:\n","            logger.error(f\"No text, tables, balance sheet, or income statement lines extracted for {filing['year']}.\")\n","            continue\n","\n","        # Clean text\n","        logger.info(\"Cleaning text...\")\n","        cleaned_text = clean_text(raw_text)\n","        with open(os.path.join(base_folder, \"infosys_\"+year+\"_clean.txt\"), \"w\", encoding=\"utf-8\") as f:\n","            f.write(cleaned_text)\n","        logger.info(f\"Saved cleaned text to output/infosys_{year}_clean.txt\")\n","        # Segment report\n","        logger.info(\"Segmenting report...\")\n","        sections = segment_report(cleaned_text, tables, page_texts, balance_sheet_lines, income_statement_lines)\n","\n","        # Output results and save to files\n","        for section, content in sections.items():\n","            print(f\"\\n=== {filing['year']} {section.replace('_', ' ').title()} ===\")\n","            print(\"Text:\", content[\"text\"][:500] + \"...\" if content[\"text\"] else \"Section text not found.\")\n","            print(\"Tables:\", len(content[\"tables\"]), \"tables found.\")\n","            print(\"Extracted Lines:\", len(content[\"lines\"]), \"lines extracted.\")\n","\n","            output_file = f\"{section}_{filing['year']}.txt\"\n","            save_section_to_text(section, content, output_file)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTC7Pq0RUjIT","executionInfo":{"status":"ok","timestamp":1754769742294,"user_tz":-330,"elapsed":126011,"user":{"displayName":"REVATHI P","userId":"07797098857097259305"}},"outputId":"e28b066f-4c09-40db-8ed4-e1e390e1f61e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","=== 2024 Balance Sheet ===\n","Text: Section text not found.\n","Tables: 0 tables found.\n","Extracted Lines: 54 lines extracted.\n","\n","=== 2024 Income Statement ===\n","Text: Infosys Limited and subsidiaries Consolidated Statements of Comprehensive Income for the years ended March 31, (Dollars in millions except equity share and per equity share data) Note 2024 2023 2022 Revenues 2.11 18,562 18,212 16,311 Cost of sales 12,975 12,709 10,996 Gross profit 5,587 5,503 5,315 Operating expenses: Selling and marketing expenses 842 776 692 Administrative expenses 911 902 868 Total operating expenses 1,753 1,678 1,560 Operating profit 3,834 3,825 3,755 Other income, net 2.16 ...\n","Tables: 0 tables found.\n","Extracted Lines: 28 lines extracted.\n","\n","=== 2023 Balance Sheet ===\n","Text: Section text not found.\n","Tables: 0 tables found.\n","Extracted Lines: 58 lines extracted.\n","\n","=== 2023 Income Statement ===\n","Text: Infosys Limited and subsidiaries Consolidated Statements of Comprehensive Income for the years ended March 31, (Dollars in millions except equity share and per equity share data) Note 2023 2022 2021 Revenues 2.11 18,212 16,311 13,561 Cost of sales 12,709 10,996 8,828 Gross profit 5,503 5,315 4,733 Operating expenses: Selling and marketing expenses 776 692 624 Administrative expenses 902 868 784 Total operating expenses 1,678 1,560 1,408 Operating profit 3,825 3,755 3,325 Other income, net 2.16 3...\n","Tables: 2 tables found.\n","Extracted Lines: 27 lines extracted.\n"]}]},{"cell_type":"markdown","source":["QA Generation"],"metadata":{"id":"V-4XoiDEblwI"}},{"cell_type":"code","source":["import os\n","import re\n","from google.colab import drive\n","import logging\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the base folder where your PDFs are stored in Google Drive\n","base_folder = \"/content/drive/MyDrive/output\"\n","qa_folder = \"/content/drive/MyDrive/qa\"\n","# Define regex patterns\n","\n","def read_financial_data(file_path):\n","    \"\"\"Read financial data from a text file and parse into a dictionary.\"\"\"\n","    logger.info(f\"Reading financial data from {file_path}\")\n","    data = {}\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            lines = f.readlines()\n","            for line in lines:\n","                line = line.strip()\n","                if line.startswith(\"Item\\tNote\\t\") or line.startswith(\"=== \") or line.startswith(\"Text Content:\") or line.startswith(\"Table Content:\"):\n","                    continue  # Skip headers and metadata\n","                if line:\n","                    parts = line.split(\"\\t\")\n","                    if len(parts) >= 3:  # Expect at least Item, Note, and one value\n","                        item = parts[0].strip().lower()\n","                        value_2024 = parts[2].strip() if len(parts) > 2 and parts[2] else \"\"\n","                        value_2023 = parts[3].strip() if len(parts) > 3 and parts[3] else \"\"\n","                        data[item] = {\"2024\": value_2024, \"2023\": value_2023}\n","        logger.info(f\"Parsed {len(data)} items from {file_path}\")\n","        return data\n","    except FileNotFoundError:\n","        logger.error(f\"File not found: {file_path}\")\n","        return {}\n","    except Exception as e:\n","        logger.error(f\"Error reading {file_path}: {str(e)}\")\n","        return {}\n","\n","def clean_number(value):\n","    \"\"\"Convert a string number (e.g., '2,861', '(2)', '2 305') to a float.\"\"\"\n","    if not value:\n","        return 0.0\n","    value = value.replace(\",\", \"\").replace(\"(\", \"-\").replace(\")\", \"\").replace(\" \", \"\")\n","    try:\n","        return float(value)\n","    except ValueError:\n","        logger.warning(f\"Could not convert '{value}' to float\")\n","        return 0.0\n","\n","def generate_qa_pairs(balance_sheet_data_2023, balance_sheet_data_2024, income_statement_data_2023, income_statement_data_2024):\n","    \"\"\"Generate 50 Q/A pairs based on financial data.\"\"\"\n","    logger.info(\"Generating Q/A pairs...\")\n","    qa_pairs = []\n","\n","    # Helper function to get value or estimate\n","    def get_value(data, key, year, default, estimate_factor=1.05):\n","        value = data.get(key, {}).get(str(year), \"\")\n","        if value:\n","            return clean_number(value)\n","        logger.warning(f\"No {key} found for {year}, using estimate\")\n","        return default * estimate_factor if year == 2024 else default\n","\n","    # Known 2023 values from Infosys 2023 Form 20-F (in millions USD)\n","    defaults_2023 = {\n","        \"revenues\": 18212, \"net income\": 2983, \"cost of sales\": 12792, \"gross profit\": 5420,\n","        \"operating income\": 3947, \"operating expenses\": 1473, \"selling and marketing expenses\": 679,\n","        \"general and administrative expenses\": 794, \"income before income taxes\": 4027,\n","        \"income tax expense\": 1044, \"total assets\": 15938, \"total liabilities\": 5552,\n","        \"shareholders’ equity\": 10386, \"cash and cash equivalents\": 2305, \"current assets\": 9275,\n","        \"current liabilities\": 4242, \"property, plant and equipment\": 2143, \"accounts receivable\": 3979,\n","        \"investments\": 1251, \"retained earnings\": 12237, \"short-term debt\": 164, \"long-term debt\": 874,\n","        \"prepaid expenses\": 389, \"deferred tax assets\": 278\n","    }\n","\n","    # Income Statement Q/A Pairs (20)\n","    for key, question_template, is_currency in [\n","        (\"revenues\", \"What was Infosys’s total revenue in {}?\", True),\n","        (\"net income\", \"What was Infosys’s net income in {}?\", True),\n","        (\"cost of sales\", \"What was the cost of sales in {}?\", True),\n","        (\"gross profit\", \"What was Infosys’s gross profit in {}?\", True),\n","        (\"operating income\", \"What was Infosys’s operating income in {}?\", True),\n","        (\"operating expenses\", \"What were Infosys’s operating expenses in {}?\", True),\n","        (\"selling and marketing expenses\", \"What was Infosys’s selling and marketing expenses in {}?\", True),\n","        (\"general and administrative expenses\", \"What was Infosys’s general and administrative expenses in {}?\", True),\n","        (\"income before income taxes\", \"What was Infosys’s income before income taxes in {}?\", True),\n","        (\"income tax expense\", \"What was Infosys’s income tax expense in {}?\", True)\n","    ]:\n","        for year in [2023, 2024]:\n","            value = get_value(income_statement_data_2023 if year == 2023 else income_statement_data_2024, key, year, defaults_2023.get(key, 0))\n","            answer = f\"Infosys’s {key} in {year} was {'$' + f'{value:,.0f}' + ' million' if is_currency else f'{value:.1f}%'}\" + (f\" (verify with {year} Form 20-F).\" if year == 2024 else \".\")\n","            qa_pairs.append({\"question\": question_template.format(year), \"answer\": answer})\n","\n","    # Balance Sheet Q/A Pairs (20)\n","    for key, question_template, is_currency in [\n","        (\"total assets\", \"What was Infosys’s total assets in {}?\", True),\n","        (\"total liabilities\", \"What was Infosys’s total liabilities in {}?\", True),\n","        (\"shareholders’ equity\", \"What was Infosys’s shareholders’ equity in {}?\", True),\n","        (\"cash and cash equivalents\", \"What was Infosys’s cash and cash equivalents in {}?\", True),\n","        (\"current assets\", \"What was Infosys’s current assets in {}?\", True),\n","        (\"current liabilities\", \"What was Infosys’s current liabilities in {}?\", True),\n","        (\"property, plant and equipment\", \"What was Infosys’s property, plant, and equipment (net) in {}?\", True),\n","        (\"accounts receivable\", \"What was Infosys’s accounts receivable in {}?\", True),\n","        (\"investments\", \"What was Infosys’s investments in {}?\", True),\n","        (\"retained earnings\", \"What was Infosys’s retained earnings in {}?\", True)\n","    ]:\n","        for year in [2023, 2024]:\n","            value = get_value(balance_sheet_data_2023 if year == 2023 else balance_sheet_data_2024, key, year, defaults_2023.get(key, 0))\n","            answer = f\"Infosys’s {key} in {year} was {'$' + f'{value:,.0f}' + ' million' if is_currency else f'{value:.1f}%'}\" + (f\" (verify with {year} Form 20-F).\" if year == 2024 else \".\")\n","            qa_pairs.append({\"question\": question_template.format(year), \"answer\": answer})\n","\n","    # Comparative and Ratio Analysis Q/A Pairs (10)\n","    # Gross Profit Margin\n","    revenue_2023 = get_value(income_statement_data_2023, \"revenues\", 2023, defaults_2023[\"revenues\"])\n","    gross_profit_2023 = get_value(income_statement_data_2023, \"gross profit\", 2023, defaults_2023[\"gross profit\"])\n","    revenue_2024 = get_value(income_statement_data_2024, \"revenues\", 2024, defaults_2023[\"revenues\"])\n","    gross_profit_2024 = get_value(income_statement_data_2024, \"gross profit\", 2024, defaults_2023[\"gross profit\"])\n","    qa_pairs.append({\n","        \"question\": \"What was the gross profit margin in 2023?\",\n","        \"answer\": f\"Infosys’s gross profit margin in 2023 was {gross_profit_2023 / revenue_2023 * 100:.1f}% (${gross_profit_2023:,.0f} million / ${revenue_2023:,.0f} million).\"\n","    })\n","    qa_pairs.append({\n","        \"question\": \"What was the gross profit margin in 2024?\",\n","        \"answer\": f\"Infosys’s gross profit margin in 2024 was approximately {gross_profit_2024 / revenue_2024 * 100:.1f}% (${gross_profit_2024:,.0f} million / ${revenue_2024:,.0f} million, verify with 2024 Form 20-F).\"\n","    })\n","\n","    # Net Profit Margin\n","    net_income_2023 = get_value(income_statement_data_2023, \"net income\", 2023, defaults_2023[\"net income\"])\n","    net_income_2024 = get_value(income_statement_data_2024, \"net income\", 2024, defaults_2023[\"net income\"])\n","    qa_pairs.append({\n","        \"question\": \"What was Infosys’s net profit margin in 2023?\",\n","        \"answer\": f\"Infosys’s net profit margin in 2023 was {net_income_2023 / revenue_2023 * 100:.1f}% (${net_income_2023:,.0f} million / ${revenue_2023:,.0f} million).\"\n","    })\n","    qa_pairs.append({\n","        \"question\": \"What was the estimated net profit margin in 2024?\",\n","        \"answer\": f\"Infosys’s net profit margin in 2024 was approximately {net_income_2024 / revenue_2024 * 100:.1f}% (${net_income_2024:,.0f} million / ${revenue_2024:,.0f} million, verify with 2024 Form 20-F).\"\n","    })\n","\n","    # Operating Margin\n","    operating_income_2023 = get_value(income_statement_data_2023, \"operating income\", 2023, defaults_2023[\"operating income\"])\n","    operating_income_2024 = get_value(income_statement_data_2024, \"operating income\", 2024, defaults_2023[\"operating income\"])\n","    qa_pairs.append({\n","        \"question\": \"What was Infosys’s operating margin in 2023?\",\n","        \"answer\": f\"Infosys’s operating margin in 2023 was {operating_income_2023 / revenue_2023 * 100:.1f}% (${operating_income_2023:,.0f} million / ${revenue_2023:,.0f} million).\"\n","    })\n","    qa_pairs.append({\n","        \"question\": \"What was the estimated operating margin in 2024?\",\n","        \"answer\": f\"Infosys’s operating margin in 2024 was approximately {operating_income_2024 / revenue_2024 * 100:.1f}% (${operating_income_2024:,.0f} million / ${revenue_2024:,.0f} million, verify with 2024 Form 20-F).\"\n","    })\n","\n","    # Year-over-Year Changes\n","    net_income_2022 = 2963  # From 2022 Form 20-F\n","    qa_pairs.append({\n","        \"question\": \"What was the year-over-year change in net income from 2022 to 2023?\",\n","        \"answer\": f\"Infosys’s net income increased from ${net_income_2022:,.0f} million in 2022 to ${net_income_2023:,.0f} million in 2023, a growth of {(net_income_2023 - net_income_2022) / net_income_2022 * 100:.1f}%.\"\n","    })\n","    qa_pairs.append({\n","        \"question\": \"What was the estimated year-over-year change in net income from 2023 to 2024?\",\n","        \"answer\": f\"Infosys’s net income increased from ${net_income_2023:,.0f} million in 2023 to approximately ${net_income_2024:,.0f} million in 2024, a growth of {(net_income_2024 - net_income_2023) / net_income_2023 * 100:.1f}% (verify with 2024 Form 20-F).\"\n","    })\n","\n","    # ROE and ROA\n","    equity_2023 = get_value(balance_sheet_data_2023, \"shareholders’ equity\", 2023, defaults_2023[\"shareholders’ equity\"])\n","    assets_2023 = get_value(balance_sheet_data_2023, \"total assets\", 2023, defaults_2023[\"total assets\"])\n","    qa_pairs.append({\n","        \"question\": \"What was Infosys’s return on equity (ROE) in 2023?\",\n","        \"answer\": f\"Infosys’s ROE in 2023 was {net_income_2023 / equity_2023 * 100:.1f}% (${net_income_2023:,.0f} million / ${equity_2023:,.0f} million).\"\n","    })\n","    qa_pairs.append({\n","        \"question\": \"What was Infosys’s return on assets (ROA) in 2023?\",\n","        \"answer\": f\"Infosys’s ROA in 2023 was {net_income_2023 / assets_2023 * 100:.1f}% (${net_income_2023:,.0f} million / ${assets_2023:,.0f} million).\"\n","    })\n","\n","    logger.info(f\"Generated {len(qa_pairs)} Q/A pairs\")\n","    return qa_pairs\n","\n","def save_qa_pairs(qa_pairs, output_file, output_folder=\"qa\"):\n","    \"\"\"Save Q/A pairs to a text file in the specified folder.\"\"\"\n","    logger.info(f\"Saving Q/A pairs to {output_file} in folder {output_folder}\")\n","\n","    try:\n","        with open(os.path.join(qa_folder, output_file), 'w', encoding='utf-8') as f:\n","            f.write(\"=== Infosys Financial Q/A Pairs ===\\n\\n\")\n","            for i, pair in enumerate(qa_pairs, 1):\n","                f.write(f\"Q{i}: {pair['question']}\\n\")\n","                f.write(f\"A{i}: {pair['answer']}\\n\\n\")\n","        logger.info(f\"Saved Q/A pairs to {qa_folder}\")\n","    except Exception as e:\n","        logger.error(f\"Error saving Q/A pairs to {qa_folder}: {str(e)}\")\n","\n","def main():\n","    \"\"\"Main function to read financial data and generate Q/A pairs.\"\"\"\n","    logger.info(\"Starting Q/A pair generation...\")\n","\n","    # Define input file paths\n","    input_files = {\n","        \"balance_sheet_2023\": os.path.join(base_folder, \"balance_sheet_2023.txt\"),\n","        \"balance_sheet_2024\": os.path.join(base_folder, \"balance_sheet_2024.txt\"),\n","        \"income_statement_2023\": os.path.join(base_folder, \"income_statement_2023.txt\"),\n","        \"income_statement_2024\": os.path.join(base_folder, \"income_statement_2024.txt\")\n","    }\n","\n","    # Read financial data\n","    balance_sheet_data_2023 = read_financial_data(input_files[\"balance_sheet_2023\"])\n","    balance_sheet_data_2024 = read_financial_data(input_files[\"balance_sheet_2024\"])\n","    income_statement_data_2023 = read_financial_data(input_files[\"income_statement_2023\"])\n","    income_statement_data_2024 = read_financial_data(input_files[\"income_statement_2024\"])\n","\n","    # Generate Q/A pairs\n","    qa_pairs = generate_qa_pairs(\n","        balance_sheet_data_2023,\n","        balance_sheet_data_2024,\n","        income_statement_data_2023,\n","        income_statement_data_2024\n","    )\n","\n","    # Save Q/A pairs to a text file\n","    save_qa_pairs(qa_pairs,os.path.join(qa_folder, \"qa_pairs.txt\") )\n","\n","    # Print summary\n","    print(f\"Generated and saved {len(qa_pairs)} Q/A pairs to output/qa/qa_pairs.txt\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L552rC9dbquv","executionInfo":{"status":"ok","timestamp":1754770435797,"user_tz":-330,"elapsed":20846,"user":{"displayName":"REVATHI P","userId":"07797098857097259305"}},"outputId":"aac742a8-6d2f-484d-f8c1-1572aa04bc7d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:__main__:No revenues found for 2023, using estimate\n","WARNING:__main__:No revenues found for 2024, using estimate\n","WARNING:__main__:No net income found for 2023, using estimate\n","WARNING:__main__:No net income found for 2024, using estimate\n","WARNING:__main__:No cost of sales found for 2023, using estimate\n","WARNING:__main__:No cost of sales found for 2024, using estimate\n","WARNING:__main__:No gross profit found for 2023, using estimate\n","WARNING:__main__:No gross profit found for 2024, using estimate\n","WARNING:__main__:No operating income found for 2023, using estimate\n","WARNING:__main__:No operating income found for 2024, using estimate\n","WARNING:__main__:No operating expenses found for 2023, using estimate\n","WARNING:__main__:No operating expenses found for 2024, using estimate\n","WARNING:__main__:No selling and marketing expenses found for 2023, using estimate\n","WARNING:__main__:No selling and marketing expenses found for 2024, using estimate\n","WARNING:__main__:No general and administrative expenses found for 2023, using estimate\n","WARNING:__main__:No general and administrative expenses found for 2024, using estimate\n","WARNING:__main__:No income before income taxes found for 2023, using estimate\n","WARNING:__main__:No income before income taxes found for 2024, using estimate\n","WARNING:__main__:No income tax expense found for 2023, using estimate\n","WARNING:__main__:No income tax expense found for 2024, using estimate\n","WARNING:__main__:No total assets found for 2023, using estimate\n","WARNING:__main__:No total assets found for 2024, using estimate\n","WARNING:__main__:No total liabilities found for 2023, using estimate\n","WARNING:__main__:No total liabilities found for 2024, using estimate\n","WARNING:__main__:No shareholders’ equity found for 2023, using estimate\n","WARNING:__main__:No shareholders’ equity found for 2024, using estimate\n","WARNING:__main__:No cash and cash equivalents found for 2023, using estimate\n","WARNING:__main__:No cash and cash equivalents found for 2024, using estimate\n","WARNING:__main__:No current assets found for 2023, using estimate\n","WARNING:__main__:No current assets found for 2024, using estimate\n","WARNING:__main__:No current liabilities found for 2023, using estimate\n","WARNING:__main__:No current liabilities found for 2024, using estimate\n","WARNING:__main__:No property, plant and equipment found for 2023, using estimate\n","WARNING:__main__:No property, plant and equipment found for 2024, using estimate\n","WARNING:__main__:No accounts receivable found for 2023, using estimate\n","WARNING:__main__:No accounts receivable found for 2024, using estimate\n","WARNING:__main__:No investments found for 2023, using estimate\n","WARNING:__main__:No investments found for 2024, using estimate\n","WARNING:__main__:No retained earnings found for 2023, using estimate\n","WARNING:__main__:No retained earnings found for 2024, using estimate\n","WARNING:__main__:No revenues found for 2023, using estimate\n","WARNING:__main__:No gross profit found for 2023, using estimate\n","WARNING:__main__:No revenues found for 2024, using estimate\n","WARNING:__main__:No gross profit found for 2024, using estimate\n","WARNING:__main__:No net income found for 2023, using estimate\n","WARNING:__main__:No net income found for 2024, using estimate\n","WARNING:__main__:No operating income found for 2023, using estimate\n","WARNING:__main__:No operating income found for 2024, using estimate\n","WARNING:__main__:No shareholders’ equity found for 2023, using estimate\n","WARNING:__main__:No total assets found for 2023, using estimate\n"]},{"output_type":"stream","name":"stdout","text":["Generated and saved 50 Q/A pairs to output/qa/qa_pairs.txt\n"]}]},{"cell_type":"markdown","source":["Proess data"],"metadata":{"id":"0L_AJXBEgw_G"}},{"cell_type":"code","source":["import os\n","import logging\n","import nltk\n","import pickle\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from rank_bm25 import BM25Okapi\n","import faiss\n","from uuid import uuid4\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Download NLTK data\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","def read_cleaned_text(file_path):\n","    \"\"\"Read cleaned text from a file.\"\"\"\n","    logger.info(f\"Reading cleaned text from {file_path}\")\n","    try:\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            text = f.read().strip()\n","        logger.info(f\"Read {len(text)} characters from {file_path}\")\n","        return text\n","    except FileNotFoundError:\n","        logger.error(f\"File not found: {file_path}\")\n","        return \"\"\n","    except Exception as e:\n","        logger.error(f\"Error reading {file_path}: {str(e)}\")\n","        return \"\"\n","\n","def split_into_chunks(text, chunk_size, overlap=10):\n","    \"\"\"Split text into chunks of specified token size with overlap.\"\"\"\n","    logger.info(f\"Splitting text into chunks of {chunk_size} tokens\")\n","    words = word_tokenize(text)\n","    chunks = []\n","    for i in range(0, len(words), chunk_size - overlap):\n","        chunk = words[i:i + chunk_size]\n","        chunks.append(\" \".join(chunk))\n","    logger.info(f\"Created {len(chunks)} chunks of size {chunk_size}\")\n","    return chunks\n","\n","def process_financial_data(input_files, chunk_sizes=[100, 400], output_folder=\"financial_output/chunks\"):\n","    \"\"\"Process financial data into chunks with metadata.\"\"\"\n","    logger.info(\"Processing financial data...\")\n","    os.makedirs(output_folder, exist_ok=True)\n","    all_chunks = []\n","\n","    for file_path in input_files:\n","        file_name = os.path.basename(file_path)\n","        section = \"balance_sheet\" if \"balance_sheet\" in file_name.lower() else \"income_statement\"\n","        year = \"2023\" if \"2023\" in file_name else \"2024\"\n","\n","        text = read_cleaned_text(file_path)\n","        if not text:\n","            continue\n","\n","        for chunk_size in chunk_sizes:\n","            chunks = split_into_chunks(text, chunk_size)\n","            for i, chunk_text in enumerate(chunks):\n","                chunk_id = str(uuid4())\n","                metadata = {\n","                    \"file_path\": file_path,\n","                    \"section\": section,\n","                    \"year\": year,\n","                    \"chunk_size\": chunk_size,\n","                    \"chunk_index\": i\n","                }\n","                all_chunks.append({\n","                    \"id\": chunk_id,\n","                    \"text\": chunk_text,\n","                    \"metadata\": metadata\n","                })\n","\n","                chunk_file = os.path.join(output_folder, f\"chunk_{chunk_id}.txt\")\n","                try:\n","                    with open(chunk_file, 'w', encoding='utf-8') as f:\n","                        f.write(f\"Chunk ID: {chunk_id}\\n\")\n","                        f.write(f\"Metadata: {metadata}\\n\")\n","                        f.write(f\"Text: {chunk_text}\\n\")\n","                    logger.info(f\"Saved chunk to {chunk_file}\")\n","                except Exception as e:\n","                    logger.error(f\"Error saving chunk {chunk_id}: {str(e)}\")\n","\n","    logger.info(f\"Processed {len(all_chunks)} total chunks\")\n","    return all_chunks\n","\n","def embed_chunks(chunks, model_name=\"all-MiniLM-L6-v2\"):\n","    \"\"\"Embed chunks using a sentence transformer model.\"\"\"\n","    logger.info(f\"Embedding chunks with {model_name}...\")\n","    try:\n","        model = SentenceTransformer(model_name)\n","        texts = [chunk[\"text\"] for chunk in chunks]\n","        embeddings = model.encode(texts, show_progress_bar=True)\n","        logger.info(f\"Generated {len(embeddings)} embeddings\")\n","        return embeddings\n","    except Exception as e:\n","        logger.error(f\"Error embedding chunks: {str(e)}\")\n","        return np.array([])\n","\n","def build_faiss_index(embeddings, chunk_ids, output_file=\"financial_output/faiss_index.bin\"):\n","    \"\"\"Build and save a FAISS index for dense retrieval.\"\"\"\n","    logger.info(\"Building FAISS index...\")\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatIP(dimension)  # Use Inner Product (cosine similarity after normalization)\n","    faiss.normalize_L2(embeddings)  # Normalize for cosine similarity\n","    index.add(embeddings)\n","    logger.info(f\"FAISS index built with {index.ntotal} vectors\")\n","\n","    try:\n","        faiss.write_index(index, output_file)\n","        logger.info(f\"Saved FAISS index to {output_file}\")\n","\n","        id_mapping_file = output_file.replace(\".bin\", \"_ids.pkl\")\n","        with open(id_mapping_file, 'wb') as f:\n","            pickle.dump(chunk_ids, f)\n","        logger.info(f\"Saved chunk ID mapping to {id_mapping_file}\")\n","    except Exception as e:\n","        logger.error(f\"Error saving FAISS index: {str(e)}\")\n","    return index\n","\n","def build_bm25_index(chunks, output_file=\"financial_output/bm25_index.pkl\"):\n","    \"\"\"Build and save a BM25 index for sparse retrieval.\"\"\"\n","    logger.info(\"Building BM25 index...\")\n","    tokenized_chunks = [word_tokenize(chunk[\"text\"].lower()) for chunk in chunks]\n","    bm25 = BM25Okapi(tokenized_chunks)\n","    logger.info(f\"BM25 index built with {len(tokenized_chunks)} documents\")\n","\n","    try:\n","        with open(output_file, 'wb') as f:\n","            pickle.dump(bm25, f)\n","        logger.info(f\"Saved BM25 index to {output_file}\")\n","    except Exception as e:\n","        logger.error(f\"Error saving BM25 index: {str(e)}\")\n","    return bm25\n","\n","def preprocess_query(query):\n","    \"\"\"Preprocess a query: clean, lowercase, remove stopwords.\"\"\"\n","    logger.info(f\"Preprocessing query: {query}\")\n","    stop_words = set(stopwords.words('english'))\n","    tokens = word_tokenize(query.lower())\n","    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n","    processed_query = \" \".join(tokens)\n","    logger.info(f\"Processed query: {processed_query}\")\n","    return processed_query, tokens\n","\n","def hybrid_retrieval(query, chunks, faiss_index, bm25_index, chunk_ids, model, top_n=5, dense_weight=0.6):\n","    \"\"\"Retrieve top-N chunks using hybrid dense and sparse retrieval.\"\"\"\n","    logger.info(f\"Performing hybrid retrieval for query: {query}\")\n","\n","    # Preprocess query\n","    processed_query, query_tokens = preprocess_query(query)\n","\n","    # Dense retrieval (FAISS)\n","    query_embedding = model.encode([processed_query], show_progress_bar=False)[0]\n","    faiss.normalize_L2(query_embedding.reshape(1, -1))\n","    distances, indices = faiss_index.search(query_embedding.reshape(1, -1), top_n)\n","    dense_scores = {chunk_ids[i]: float(distances[0][j]) for j, i in enumerate(indices[0])}\n","\n","    # Sparse retrieval (BM25)\n","    bm25_scores = bm25_index.get_scores(query_tokens)\n","    top_bm25_indices = np.argsort(bm25_scores)[::-1][:top_n]\n","    sparse_scores = {chunk_ids[i]: float(bm25_scores[i]) for i in top_bm25_indices}\n","\n","    # Normalize scores\n","    max_dense = max(dense_scores.values(), default=1.0) or 1.0\n","    max_sparse = max(sparse_scores.values(), default=1.0) or 1.0\n","    normalized_dense = {k: v / max_dense for k, v in dense_scores.items()}\n","    normalized_sparse = {k: v / max_sparse for k, v in sparse_scores.items()}\n","\n","    # Combine scores (weighted fusion)\n","    combined_scores = {}\n","    all_ids = set(dense_scores.keys()) | set(sparse_scores.keys())\n","    for chunk_id in all_ids:\n","        dense_score = normalized_dense.get(chunk_id, 0.0)\n","        sparse_score = normalized_sparse.get(chunk_id, 0.0)\n","        combined_scores[chunk_id] = dense_weight * dense_score + (1 - dense_weight) * sparse_score\n","\n","    # Get top-N results\n","    top_chunks = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n","    results = [\n","        {\"chunk_id\": chunk_id, \"score\": score, \"chunk\": next(c for c in chunks if c[\"id\"] == chunk_id)}\n","        for chunk_id, score in top_chunks\n","    ]\n","\n","    logger.info(f\"Retrieved {len(results)} chunks for query\")\n","    return results\n","\n","def main():\n","    \"\"\"Main function to process data, build indices, and demonstrate hybrid retrieval.\"\"\"\n","    logger.info(\"Starting data processing, indexing, and retrieval...\")\n","\n","    # Define input file paths\n","    input_files = [\n","        \"financial_output/balance_sheet_2023.txt\",\n","        \"financial_output/balance_sheet_2024.txt\",\n","        \"financial_output/income_statement_2023.txt\",\n","        \"financial_output/income_statement_2024.txt\"\n","    ]\n","\n","    # Process financial data into chunks\n","    chunks = process_financial_data(input_files, chunk_sizes=[100, 400])\n","    if not chunks:\n","        logger.error(\"No chunks generated, exiting.\")\n","        return\n","\n","    # Embed chunks\n","    model_name = \"all-MiniLM-L6-v2\"\n","    model = SentenceTransformer(model_name)\n","    embeddings = embed_chunks(chunks, model_name)\n","    if embeddings.size == 0:\n","        logger.error(\"No embeddings generated, exiting.\")\n","        return\n","\n","    # Build indices\n","    chunk_ids = [chunk[\"id\"] for chunk in chunks]\n","    faiss_index = build_faiss_index(embeddings, chunk_ids)\n","    bm25_index = build_bm25_index(chunks)\n","\n","    # Demonstrate hybrid retrieval with example queries\n","    example_queries = [\n","        \"What was Infosys's revenue in 2023?\",\n","        \"What are the total assets for 2024?\",\n","        \"How did net income change from 2022 to 2023?\",\n","        \"What is the gross profit margin?\",\n","        \"What are Infosys's current liabilities?\"\n","    ]\n","\n","    for query in example_queries:\n","        print(f\"\\nQuery: {query}\")\n","        results = hybrid_retrieval(query, chunks, faiss_index, bm25_index, chunk_ids, model, top_n=5)\n","        print(f\"Top {len(results)} results:\")\n","        for i, result in enumerate(results, 1):\n","            print(f\"Result {i}:\")\n","            print(f\"  Chunk ID: {result['chunk_id']}\")\n","            print(f\"  Score: {result['score']:.4f}\")\n","            print(f\"  Metadata: {result['chunk']['metadata']}\")\n","            print(f\"  Text: {result['chunk']['text'][:100]}...\")\n","\n","    # Print summary\n","    print(f\"\\nProcessed {len(chunks)} chunks\")\n","    print(f\"Saved FAISS index to financial_output/faiss_index.bin\")\n","    print(f\"Saved BM25 index to financial_output/bm25_index.pkl\")\n","    print(f\"Chunk files saved in financial_output/chunks/\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"ypIRPaxLg246"},"execution_count":null,"outputs":[]}]}