{"cells":[{"cell_type":"markdown","metadata":{"id":"MymuL4xnKQqR"},"source":["# Assignment 2: Comparative Financial QA System - RAG vs Fine-Tuning\n","\n","**Group Number**: X (Replace with your group number)\n","\n","**Objective**: Develop and compare a Retrieval-Augmented Generation (RAG) chatbot and a Fine-Tuned Language Model (FT) chatbot for answering questions based on Infosys financial statements (2023 and 2024). The RAG system uses hybrid search (sparse + dense retrieval), and the fine-tuning uses retrieval-augmented fine-tuning.\n","\n","**Data**: Infosys financial statements for 2023 and 2024, processed into balance sheets and income statements.\n","\n","**Structure**:\n","1. Data Collection & Preprocessing\n","2. RAG System Implementation (Hybrid Search)\n","3. Fine-Tuned Model Implementation (Retrieval-Augmented Fine-Tuning)\n","4. Testing, Evaluation & Comparison\n","5. Streamlit Interface\n","\n","**Note**: Ensure all dependencies (PyMuPDF, pdfplumber, pytesseract, pdf2image, sentence-transformers, faiss, rank-bm25, nltk, streamlit, transformers) are installed."],"id":"MymuL4xnKQqR"},{"cell_type":"markdown","metadata":{"id":"vpelBbVDKQqW"},"source":["## 1. Data Collection & Preprocessing"],"id":"vpelBbVDKQqW"},{"cell_type":"code","metadata":{"id":"kZ6uSKDEKQqX"},"source":["import fitz  # PyMuPDF\n","import pytesseract\n","from pdf2image import convert_from_path\n","import os\n","import logging\n","import pdfplumber\n","import re\n","from collections import Counter\n","import json\n","from uuid import uuid4\n","\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n","logger = logging.getLogger(__name__)\n","\n","# 1.1 Extract Text from PDFs\n","def pdf_to_text(pdf_path, ocr=False):\n","    \"\"\"Extract text from a PDF, preserving the natural reading order.\"\"\"\n","    logger.info(f\"Extracting text from {pdf_path}...\")\n","    full_text = \"\"\n","    try:\n","        if not ocr:\n","            with pdfplumber.open(pdf_path) as pdf:\n","                for page in pdf.pages:\n","                    page_text = page.extract_text(layout=True, x_tolerance=2)\n","                    if page_text:\n","                        full_text += page_text + \"\\n\"\n","            logger.info(f\"Direct text extracted from {pdf_path} in reading order.\")\n","        else:\n","            images = convert_from_path(pdf_path)\n","            for i, img in enumerate(images):\n","                full_text += pytesseract.image_to_string(img) + \"\\n\"\n","                logger.info(f\"OCR processed page {i+1}/{len(images)}\")\n","        return full_text.strip()\n","    except Exception as e:\n","        logger.error(f\"Error extracting text from {pdf_path}: {e}\")\n","        return \"\"\n","\n","# 1.2 Clean Text\n","def clean_text(raw_text):\n","    \"\"\"Clean raw text by removing page numbers, headers, footers, and extra whitespace.\"\"\"\n","    logger.info(\"Text cleaning started...\")\n","    try:\n","        text = re.sub(r'Page\\s+\\d+\\s+of\\s+\\d+', '', raw_text, flags=re.IGNORECASE)\n","        text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n","        text = re.sub(r'Infosys Limited and subsidiaries', '', text, flags=re.IGNORECASE)\n","        text = re.sub(r'Annual Report \\d{4}', '', text, flags=re.IGNORECASE)\n","        text = re.sub(r'\\n\\s*\\n+', '\\n', text)\n","        text = re.sub(r'\\s+', ' ', text).strip()\n","        logger.info(\"Text cleaned successfully...\")\n","        return text\n","    except Exception as e:\n","        logger.error(f\"Error cleaning text: {e}\")\n","        return raw_text\n","\n","# 1.3 Segment Report\n","def segment_report(text: str) -> dict:\n","    \"\"\"Segments the cleaned text into logical sections like balance sheet and income statement.\"\"\"\n","    logger.info(\"Segmenting report into logical sections...\")\n","    sections = {}\n","    patterns = {\n","        'income_statement': re.compile(r'Consolidated Statements of Comprehensive Income for the years ended March 31, \\(Dollars in millions.*?Diluted \\(in \\$ per share\\).*?\\d+\\.\\d+', re.IGNORECASE | re.DOTALL),\n","        'balance_sheet': re.compile(r'Consolidated Balance Sheet as of March 31, \\(Dollars in millions.*?Total liabilities and equity.*?\\d{1,3}(?:,\\d{3})*', re.IGNORECASE | re.DOTALL)\n","    }\n","    for section_name, pattern in patterns.items():\n","        match = pattern.search(text)\n","        if match:\n","            sections[section_name] = match.group(0).strip()\n","            logger.info(f\"Found and extracted '{section_name}'.\")\n","        else:\n","            sections[section_name] = \"Not found\"\n","            logger.warning(f\"Could not find '{section_name}'.\")\n","    return sections\n","\n","# 1.4 Generate Q&A Pairs\n","def generate_qa_from_text(text_content, file_path):\n","    \"\"\"Generates Q&A pairs from a block of financial text.\"\"\"\n","    qa_pairs = []\n","    year_match = re.search(r'_(\\d{4})_', file_path)\n","    if not year_match:\n","        return []\n","    main_year = int(year_match.group(1))\n","    if \"income_statement\" in file_path:\n","        years = (main_year, main_year - 1, main_year - 2)\n","    else:\n","        years = (main_year, main_year - 1)\n","    text_data = ' '.join(text_content.split())\n","    header_pattern = re.compile(r'.*?\\(Dollars in millions.*?data\\)\\s*Note\\s*', re.IGNORECASE)\n","    text_data = header_pattern.sub('', text_data)\n","    val_pattern = r'[\\d,.-]+|\\([\\d,.-]+\\)'\n","    delimiter_pattern_3_col = re.compile(f'\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s*')\n","    delimiter_pattern_2_col = re.compile(f'\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s*')\n","    parts = []\n","    if \"income_statement\" in file_path:\n","        temp_parts = delimiter_pattern_3_col.split(text_data)\n","        for part in temp_parts:\n","            parts.extend(delimiter_pattern_2_col.split(part))\n","    else:\n","        parts = delimiter_pattern_2_col.split(text_data)\n","    i = 0\n","    while i < len(parts):\n","        item_name = parts[i].strip().lower().rstrip('.-â€“: ')\n","        num_values = 0\n","        if (i + 1 < len(parts)) and re.fullmatch(val_pattern, parts[i+1].strip()):\n","            num_values = 1\n","            if (i + 2 < len(parts)) and re.fullmatch(val_pattern, parts[i+2].strip()):\n","                num_values = 2\n","                if (i + 3 < len(parts)) and re.fullmatch(val_pattern, parts[i+3].strip()):\n","                    num_values = 3\n","        if item_name and num_values > 0:\n","            values = parts[i+1 : i+1+num_values]\n","            for j, year in enumerate(years):\n","                if j < len(values) and values[j]:\n","                    question = f\"What was the {item_name} in {year}?\"\n","                    answer = f\"For the year {year}, the {item_name} was ${values[j]} million.\"\n","                    qa_pairs.append({\"question\": question, \"answer\": answer})\n","            i += (1 + num_values)\n","        else:\n","            i += 1\n","    return qa_pairs\n","\n","# Preprocessing Pipeline\n","files = [\"data/raw/infosys_2023.pdf\", \"data/raw/infosys_2024.pdf\"]\n","os.makedirs(\"data/output\", exist_ok=True)\n","os.makedirs(\"data/clean\", exist_ok=True)\n","os.makedirs(\"data/segmented\", exist_ok=True)\n","os.makedirs(\"data/qa\", exist_ok=True)\n","\n","all_qa_pairs = []\n","for file_path in files:\n","    year = os.path.basename(file_path).split(\"_\")[1].split(\".\")[0]\n","    logger.info(f\"Processing {file_path} for year {year}\")\n","    raw_text = pdf_to_text(file_path, ocr=False)\n","    if not raw_text:\n","        logger.warning(f\"Direct extraction failed for {file_path}, trying OCR\")\n","        raw_text = pdf_to_text(file_path, ocr=True)\n","    if not raw_text:\n","        logger.error(f\"Failed to extract text from {file_path}\")\n","        continue\n","    cleaned_text = clean_text(raw_text)\n","    cleaned_text_path = f\"data/clean/infosys_{year}_cleaned.txt\"\n","    with open(cleaned_text_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(cleaned_text)\n","    sections = segment_report(cleaned_text)\n","    for name, content in sections.items():\n","        if content != \"Not found\":\n","            segmented_path = f\"data/segmented/infosys_{year}_{name}.txt\"\n","            with open(segmented_path, \"w\", encoding=\"utf-8\") as f:\n","                f.write(content)\n","            logger.info(f\"Saved {name} to {segmented_path}\")\n","            qa_pairs = generate_qa_from_text(content, segmented_path)\n","            all_qa_pairs.extend(qa_pairs)\n","\n","with open(\"data/qa/financial_qa_pairs.json\", 'w', encoding='utf-8') as f:\n","    json.dump(all_qa_pairs, f, indent=4)\n","logger.info(f\"Generated {len(all_qa_pairs)} Q&A pairs and saved to data/qa/financial_qa_pairs.json\")"],"outputs":[],"id":"kZ6uSKDEKQqX","execution_count":null},{"cell_type":"markdown","metadata":{"id":"naAlyVFSKQqa"},"source":["## 2. RAG System Implementation (Hybrid Search)"],"id":"naAlyVFSKQqa"},{"cell_type":"code","metadata":{"id":"oOmLpQ3iKQqa"},"source":["import nltk\n","from sentence_transformers import SentenceTransformer\n","from rank_bm25 import BM25Okapi\n","import faiss\n","import numpy as np\n","from transformers import pipeline, AutoTokenizer\n","import streamlit as st\n","import time\n","\n","nltk.download('punkt', quiet=True)\n","\n","# 2.1 Data Processing (Chunking)\n","def create_sentence_chunks(text_content, file_path, chunk_size=100):\n","    \"\"\"Processes a block of financial text into chunks of specified token size.\"\"\"\n","    logger.info(f\"Creating sentence chunks for {os.path.basename(file_path)} with chunk_size={chunk_size}\")\n","    file_name = os.path.basename(file_path)\n","    section = \"balance_sheet\" if \"balance_sheet\" in file_name.lower() else \"income_statement\"\n","    year_match = re.search(r'_(\\d{4})_', file_name)\n","    if not year_match:\n","        logger.warning(f\"Could not determine year from filename: {file_name}\")\n","        return []\n","    main_year = int(year_match.group(1))\n","    years = (main_year, main_year - 1, main_year - 2) if \"income_statement\" in section else (main_year, main_year - 1)\n","    generated_chunks = []\n","    text_data = ' '.join(text_content.split())\n","    header_pattern = re.compile(r'.*?\\(Dollars in millions.*?data\\)\\s*Note\\s*', re.IGNORECASE)\n","    text_data = header_pattern.sub('', text_data)\n","    val_pattern = r'[\\d,.-]+|\\([\\d,.-]+\\)'\n","    delimiter_pattern_3_col = re.compile(f'\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s*')\n","    delimiter_pattern_2_col = re.compile(f'\\\\s+({val_pattern})\\\\s+({val_pattern})\\\\s*')\n","    parts = []\n","    if \"income_statement\" in section:\n","        temp_parts = delimiter_pattern_3_col.split(text_data)\n","        for part in temp_parts:\n","            parts.extend(delimiter_pattern_2_col.split(part))\n","    else:\n","        parts = delimiter_pattern_2_col.split(text_data)\n","    i = 0\n","    current_chunk = []\n","    current_tokens = 0\n","    tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n","    while i < len(parts):\n","        item_name = parts[i].strip().lower().rstrip('.-â€“: ')\n","        num_values = 0\n","        if (i + 1 < len(parts)) and re.fullmatch(val_pattern, parts[i+1].strip()):\n","            num_values = 1\n","            if (i + 2 < len(parts)) and re.fullmatch(val_pattern, parts[i+2].strip()):\n","                num_values = 2\n","                if (i + 3 < len(parts)) and re.fullmatch(val_pattern, parts[i+3].strip()):\n","                    num_values = 3\n","        if item_name and num_values > 0:\n","            values = parts[i+1 : i+1+num_values]\n","            for j, year in enumerate(years):\n","                if j < len(values):\n","                    value_str = values[j]\n","                    clean_val = value_str.strip().replace(\",\", \"\")\n","                    sentence = f\"For the year {year}, the {item_name} was ${clean_val} million.\"\n","                    tokens = len(tokenizer.encode(sentence))\n","                    if current_tokens + tokens > chunk_size and current_chunk:\n","                        generated_chunks.append({\n","                            \"id\": str(uuid4()),\n","                            \"text\": \" \".join(current_chunk),\n","                            \"metadata\": {\"file_path\": file_path, \"section\": section, \"year\": year, \"original_item\": item_name}\n","                        })\n","                        current_chunk = [sentence]\n","                        current_tokens = tokens\n","                    else:\n","                        current_chunk.append(sentence)\n","                        current_tokens += tokens\n","            i += (1 + num_values)\n","        else:\n","            i += 1\n","    if current_chunk:\n","        generated_chunks.append({\n","            \"id\": str(uuid4()),\n","            \"text\": \" \".join(current_chunk),\n","            \"metadata\": {\"file_path\": file_path, \"section\": section, \"year\": year, \"original_item\": item_name}\n","        })\n","    logger.info(f\"Generated {len(generated_chunks)} chunks from {file_name}.\")\n","    return generated_chunks\n","\n","# 2.2 Embedding & Indexing\n","def embed_chunks(chunks, model_name=\"intfloat/e5-small-v2\"):\n","    logger.info(f\"Embedding chunks with {model_name}...\")\n","    try:\n","        model = SentenceTransformer(model_name)\n","        texts = [f\"passage: {chunk['text']}\" for chunk in chunks]\n","        return model.encode(texts, show_progress_bar=True, normalize_embeddings=True)\n","    except Exception as e:\n","        logger.error(f\"Error embedding chunks: {e}\")\n","        return np.array([])\n","\n","def build_faiss_index(embeddings, chunk_ids, output_dir=\"data/retrieval\"):\n","    logger.info(\"Building FAISS index...\")\n","    os.makedirs(output_dir, exist_ok=True)\n","    dimension = embeddings.shape[1]\n","    index = faiss.IndexFlatIP(dimension)\n","    index.add(embeddings)\n","    faiss.write_index(index, f\"{output_dir}/faiss_index.bin\")\n","    with open(f\"{output_dir}/faiss_index_ids.pkl\", 'wb') as f:\n","        pickle.dump(chunk_ids, f)\n","    logger.info(f\"Saved FAISS index with {index.ntotal} vectors.\")\n","\n","def build_bm25_index(chunks, output_dir=\"data/retrieval\"):\n","    logger.info(\"Building BM25 index...\")\n","    os.makedirs(output_dir, exist_ok=True)\n","    tokenized_chunks = [word_tokenize(chunk[\"text\"].lower()) for chunk in chunks]\n","    bm25 = BM25Okapi(tokenized_chunks)\n","    with open(f\"{output_dir}/bm25_index.pkl\", 'wb') as f:\n","        pickle.dump(bm25, f)\n","    logger.info(f\"Saved BM25 index with {len(tokenized_chunks)} documents.\")\n","\n","# Process chunks with two sizes: 100 and 400 tokens\n","input_files = [\n","    \"data/segmented/infosys_2023_balance_sheet.txt\",\n","    \"data/segmented/infosys_2024_balance_sheet.txt\",\n","    \"data/segmented/infosys_2023_income_statement.txt\",\n","    \"data/segmented/infosys_2024_income_statement.txt\"\n","]\n","chunk_sizes = [100, 400]\n","all_chunks = []\n","for size in chunk_sizes:\n","    for file_path in input_files:\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            text = f.read().strip()\n","        chunks = create_sentence_chunks(text, file_path, chunk_size=size)\n","        all_chunks.extend(chunks)\n","with open(\"data/chunks/all_sentence_chunks.json\", 'w', encoding='utf-8') as f:\n","    json.dump(all_chunks, f, indent=4)\n","chunks = all_chunks\n","embeddings = embed_chunks(chunks)\n","chunk_ids = [chunk[\"id\"] for chunk in chunks]\n","build_faiss_index(embeddings, chunk_ids)\n","build_bm25_index(chunks)\n","\n","# 2.3 & 2.4 Hybrid Retrieval Pipeline\n","class RetrievalConfig:\n","    INITIAL_CANDIDATE_COUNT = 80\n","    BM25_TOP_MULTIPLIER = 2\n","    DENSE_WEIGHT = 0.5\n","    SPARSE_WEIGHT = 0.5\n","    FINAL_TOP_K = 8\n","    CTX_MAX_TOKENS = 900\n","    EMB_MODEL_NAME = \"intfloat/e5-small-v2\"\n","    GEN_MODEL_NAME = \"distilgpt2\"\n","    FAISS_INDEX_IS_INNER_PRODUCT = True\n","\n","def preprocess_query(query: str) -> Tuple[str, List[str]]:\n","    stop_words = set(nltk.corpus.stopwords.words('english'))\n","    tokens = word_tokenize(query.lower())\n","    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n","    return \" \".join(filtered_tokens), filtered_tokens\n","\n","def _normalize_minmax(d: Dict[int, float]) -> Dict[int, float]:\n","    if not d:\n","        return d\n","    vals = list(d.values())\n","    vmin, vmax = min(vals), max(vals)\n","    if vmax - vmin < 1e-9:\n","        return {k: 1.0 for k in d}\n","    return {k: (v - vmin) / (vmax - vmin) for k, v in d.items()}\n","\n","def _faiss_scores_to_similarity(distances: np.ndarray) -> np.ndarray:\n","    if RetrievalConfig.FAISS_INDEX_IS_INNER_PRODUCT:\n","        return distances\n","    return -distances\n","\n","def hybrid_retrieval(query: str, chunks: List[Dict], faiss_index: faiss.Index, bm25: BM25Okapi, chunk_ids: List[int], emb_model: SentenceTransformer) -> Tuple[List[Dict], List[float]]:\n","    logger.info(f\"Hybrid retrieval for query: {query}\")\n","    processed_query, query_tokens = preprocess_query(query)\n","    q_emb = emb_model.encode([f\"query: {processed_query}\"], show_progress_bar=False, normalize_embeddings=True)[0]\n","    distances, indices = faiss_index.search(q_emb.reshape(1, -1), RetrievalConfig.INITIAL_CANDIDATE_COUNT)\n","    sim = _faiss_scores_to_similarity(distances)[0]\n","    dense_scores = {chunk_ids[i]: float(sim[j]) for j, i in enumerate(indices[0]) if i != -1}\n","    bm25_scores = bm25.get_scores(query_tokens)\n","    top_bm25_idx = np.argsort(bm25_scores)[::-1][:RetrievalConfig.INITIAL_CANDIDATE_COUNT * RetrievalConfig.BM25_TOP_MULTIPLIER]\n","    sparse_scores = {chunk_ids[i]: float(bm25_scores[i]) for i in top_bm25_idx}\n","    dn = _normalize_minmax(dense_scores)\n","    sn = _normalize_minmax(sparse_scores)\n","    combined = {cid: RetrievalConfig.DENSE_WEIGHT * dn.get(cid, 0.0) + RetrievalConfig.SPARSE_WEIGHT * sn.get(cid, 0.0) for cid in set(dn) | set(sn)}\n","    top_ids = sorted(combined, key=combined.get, reverse=True)\n","    seen_texts = set()\n","    candidate_chunks = []\n","    candidate_scores = []\n","    for cid in top_ids:\n","        chunk = next((c for c in chunks if c[\"id\"] == cid), None)\n","        if chunk and chunk[\"text\"].strip() not in seen_texts:\n","            seen_texts.add(chunk[\"text\"].strip())\n","            candidate_chunks.append(chunk)\n","            candidate_scores.append(combined.get(cid, 0.0))\n","        if len(candidate_chunks) >= RetrievalConfig.FINAL_TOP_K:\n","            break\n","    return candidate_chunks, candidate_scores\n","\n","# 2.5 Response Generation\n","def rag_generate(query: str, retrieved_chunks: List[Dict], cfg: RetrievalConfig) -> str:\n","    logger.info(\"Generating answer from merged chunks...\")\n","    if not retrieved_chunks:\n","        return \"No relevant information was found to generate an answer.\"\n","    number_pattern = re.compile(r\"\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?(?:\\s*(?:million|billion|mn|bn|m|b))\\b\", re.IGNORECASE)\n","    year_pattern = re.compile(r\"^(19|20)\\d{2}$\")\n","    keyword_variants = [\"total assets\", \"total asset\", \"assets total\", \"total liabilities\", \"total equity\", \"cash and cash equivalents\", \"revenues\", \"net profit\", \"income tax expense\"]\n","\n","    def find_number_near_keyword(chunks, keywords, window_chars=200):\n","        query_keywords = [kw for kw in keywords if kw in query.lower()]\n","        for chunk in chunks:\n","            txt = chunk.get(\"text\", \"\").lower()\n","            for kw in query_keywords:\n","                idx = txt.find(kw)\n","                if idx != -1:\n","                    start = max(0, idx - 50)\n","                    end = min(len(txt), idx + window_chars)\n","                    window = txt[start:end]\n","                    m = number_pattern.search(window)\n","                    if m:\n","                        val = m.group(0).strip()\n","                        if not year_pattern.match(val.replace(\"$\", \"\").replace(\",\", \"\")):\n","                            return val, chunk\n","        for chunk in chunks:\n","            m = number_pattern.search(chunk.get(\"text\", \"\"))\n","            if m:\n","                val = m.group(0).strip()\n","                if not year_pattern.match(val.replace(\"$\", \"\").replace(\",\", \"\")):\n","                    return val, chunk\n","        return None, None\n","\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.GEN_MODEL_NAME)\n","    context_parts = []\n","    token_budget = cfg.CTX_MAX_TOKENS\n","    for ch in retrieved_chunks:\n","        t = ch.get(\"text\", \"\").strip()\n","        tokens = tokenizer(t, return_tensors='pt')['input_ids'].shape[1]\n","        if tokens <= token_budget:\n","            context_parts.append(t)\n","            token_budget -= tokens\n","        if token_budget <= 0:\n","            break\n","    context = \"\\n\\n\".join(context_parts)\n","\n","    numeric_query = bool(re.search(r\"\\b(19|20)\\d{2}\\b\", query)) or any(w in query.lower() for w in [\"assets\", \"revenue\", \"profit\", \"income\", \"liabilities\", \"cash\"])\n","    if numeric_query:\n","        match_text, match_chunk = find_number_near_keyword(retrieved_chunks, keyword_variants)\n","        if match_text:\n","            src = match_chunk.get(\"metadata\", {}).get(\"file_path\", \"unknown\")\n","            return match_text\n","\n","    prompt = (\n","        \"You are a precise financial assistant. Answer ONLY using the exact words or numbers from the context.\\n\"\n","        \"If the exact answer is not present, reply 'Not found'. Do not invent numbers.\\n\\n\"\n","        f\"Context:\\n{context}\\n\\n\"\n","        f\"Question: {query}\\nAnswer:\"\n","    )\n","\n","    inputs = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=1024)\n","    truncated_prompt = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n","    try:\n","        generator = pipeline('text-generation', model=cfg.GEN_MODEL_NAME, device=-1)\n","        response = generator(\n","            truncated_prompt,\n","            max_new_tokens=120,\n","            do_sample=False,\n","            num_return_sequences=1,\n","            pad_token_id=tokenizer.eos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )[0]['generated_text']\n","        answer = response.replace(truncated_prompt, \"\").strip().split('\\n')[0].strip()\n","        return answer\n","    except Exception as e:\n","        logger.error(f\"Error during generation: {e}\")\n","        return \"An error occurred while generating the answer.\"\n","\n","# 2.6 Guardrail Implementation (Input-side)\n","def validate_query(query: str) -> bool:\n","    \"\"\"Validate query to ensure it's relevant to financial data.\"\"\"\n","    financial_keywords = [\"revenue\", \"profit\", \"assets\", \"liabilities\", \"equity\", \"income\", \"cash\", \"balance\", \"statement\", \"financial\", \"2023\", \"2024\"]\n","    query_lower = query.lower()\n","    if len(query.strip()) < 5 or not any(keyword in query_lower for keyword in financial_keywords):\n","        logger.warning(f\"Invalid query: {query}. Must contain financial keywords or be specific.\")\n","        return False\n","    return True\n"],"outputs":[],"id":"oOmLpQ3iKQqa","execution_count":null},{"cell_type":"markdown","metadata":{"id":"9FlZDG96KQqc"},"source":["## 3. Fine-Tuned Model Implementation (Retrieval-Augmented Fine-Tuning)"],"id":"9FlZDG96KQqc"},{"cell_type":"code","metadata":{"id":"DJNO98NeKQqd"},"source":["from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n","from datasets import Dataset\n","import pickle\n","\n","# 3.1 Q/A Dataset Preparation\n","def prepare_fine_tuning_dataset(qa_pairs):\n","    \"\"\"Convert Q/A pairs into a fine-tuning dataset format.\"\"\"\n","    data = [{\"text\": f\"Question: {pair['question']}\\nAnswer: {pair['answer']}\"} for pair in qa_pairs]\n","    return Dataset.from_list(data)\n","\n","# 3.2 Model Selection\n","model_name = \"distilgpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# 3.3 Baseline Benchmarking\n","def evaluate_baseline_model(model, tokenizer, test_questions):\n","    results = []\n","    generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=-1)\n","    for question in test_questions:\n","        start_time = time.time()\n","        prompt = f\"Question: {question}\\nAnswer:\"\n","        response = generator(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n","        answer = response.replace(prompt, \"\").strip()\n","        elapsed = time.time() - start_time\n","        results.append({\"question\": question, \"answer\": answer, \"time\": elapsed})\n","    return results\n","\n","# 3.4 & 3.5 Retrieval-Augmented Fine-Tuning\n","def fine_tune_model(dataset, chunks, faiss_index, chunk_ids, bm25, emb_model):\n","    \"\"\"Fine-tune model with retrieval-augmented data.\"\"\"\n","    logger.info(\"Starting retrieval-augmented fine-tuning...\")\n","    augmented_data = []\n","    for item in dataset:\n","        question = item['text'].split(\"\\nAnswer:\")[0].replace(\"Question: \", \"\").strip()\n","        retrieved_chunks, _ = hybrid_retrieval(question, chunks, faiss_index, bm25, chunk_ids, emb_model)\n","        context = \"\\n\".join([chunk['text'] for chunk in retrieved_chunks[:3]])\n","        augmented_data.append({\"text\": f\"Context: {context}\\n{item['text']}\"})\n","    augmented_dataset = Dataset.from_list(augmented_data)\n","\n","    def tokenize_function(examples):\n","        return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n","\n","    tokenized_dataset = augmented_dataset.map(tokenize_function, batched=True)\n","    training_args = TrainingArguments(\n","        output_dir=\"./fine_tuned_model\",\n","        num_train_epochs=3,\n","        per_device_train_batch_size=4,\n","        learning_rate=5e-5,\n","        logging_dir='./logs',\n","        logging_steps=10,\n","        save_strategy=\"epoch\"\n","    )\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_dataset\n","    )\n","    trainer.train()\n","    model.save_pretrained(\"./fine_tuned_model\")\n","    tokenizer.save_pretrained(\"./fine_tuned_model\")\n","    logger.info(\"Fine-tuning completed and model saved.\")\n","\n","# 3.6 Guardrail Implementation (Output-side)\n","def validate_output(output: str) -> bool:\n","    \"\"\"Check if output contains financial data or is relevant.\"\"\"\n","    number_pattern = re.compile(r\"\\$?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?(?:\\s*(?:million|billion|mn|bn|m|b))\\b\", re.IGNORECASE)\n","    if not number_pattern.search(output) and \"not found\" not in output.lower():\n","        logger.warning(f\"Output may be hallucinated: {output}\")\n","        return False\n","    return True\n","\n","# Run Fine-Tuning\n","with open(\"data/qa/financial_qa_pairs.json\", 'r', encoding='utf-8') as f:\n","    qa_pairs = json.load(f)\n","dataset = prepare_fine_tuning_dataset(qa_pairs)\n","emb_model = SentenceTransformer(RetrievalConfig.EMB_MODEL_NAME)\n","chunks = json.load(open(\"data/chunks/all_sentence_chunks.json\", 'r', encoding='utf-8'))\n","faiss_index = faiss.read_index(\"data/retrieval/faiss_index.bin\")\n","with open(\"data/retrieval/faiss_index_ids.pkl\", 'rb') as f:\n","    chunk_ids = pickle.load(f)\n","with open(\"data/retrieval/bm25_index.pkl\", 'rb') as f:\n","    bm25 = pickle.load(f)\n","fine_tune_model(dataset, chunks, faiss_index, chunk_ids, bm25, emb_model)\n","\n","# Baseline Evaluation\n","test_questions = [\n","    \"What was the total assets in 2023?\",\n","    \"What was the net profit in 2024?\",\n","    # Add more test questions\n","]\n","baseline_results = evaluate_baseline_model(model, tokenizer, test_questions)"],"outputs":[],"id":"DJNO98NeKQqd","execution_count":null},{"cell_type":"markdown","metadata":{"id":"GXvvchHiKQqd"},"source":["## 4. Testing, Evaluation & Comparison"],"id":"GXvvchHiKQqd"},{"cell_type":"code","metadata":{"id":"RoRmLSMFKQqe"},"source":["# 4.1 Test Questions\n","test_questions = [\n","    {\"question\": \"What was the total assets in 2023?\", \"ground_truth\": \"$15,312 million\", \"type\": \"high-confidence\"},\n","    {\"question\": \"What was the operating margin in 2023?\", \"ground_truth\": \"Not explicitly stated\", \"type\": \"low-confidence\"},\n","    {\"question\": \"What is the capital of France?\", \"ground_truth\": \"Not applicable\", \"type\": \"irrelevant\"},\n","    # Add more test questions to reach at least 10\n","]\n","\n","# 4.2 Extended Evaluation\n","def evaluate_systems(rag_func, ft_model, ft_tokenizer, test_questions, chunks, faiss_index, bm25, chunk_ids, emb_model):\n","    results = []\n","    ft_generator = pipeline('text-generation', model=ft_model, tokenizer=ft_tokenizer, device=-1)\n","    for q in test_questions:\n","        question = q[\"question\"]\n","        ground_truth = q[\"ground_truth\"]\n","        # RAG Evaluation\n","        start_time = time.time()\n","        if validate_query(question):\n","            retrieved_chunks, scores = hybrid_retrieval(question, chunks, faiss_index, bm25, chunk_ids, emb_model)\n","            rag_answer = rag_generate(question, retrieved_chunks, RetrievalConfig)\n","            rag_confidence = max(scores) if scores else 0.0\n","        else:\n","            rag_answer = \"Invalid query\"\n","            rag_confidence = 0.0\n","        rag_time = time.time() - start_time\n","        rag_correct = rag_answer == ground_truth or (ground_truth == \"Not explicitly stated\" and \"not found\" in rag_answer.lower())\n","        # Fine-Tuned Evaluation\n","        start_time = time.time()\n","        prompt = f\"Question: {question}\\nAnswer:\"\n","        ft_response = ft_generator(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n","        ft_answer = ft_response.replace(prompt, \"\").strip()\n","        ft_time = time.time() - start_time\n","        ft_correct = ft_answer == ground_truth or (ground_truth == \"Not explicitly stated\" and \"not found\" in ft_answer.lower())\n","        ft_confidence = 1.0 if validate_output(ft_answer) else 0.5\n","        results.append({\n","            \"question\": question,\n","            \"method\": \"RAG\",\n","            \"answer\": rag_answer,\n","            \"confidence\": rag_confidence,\n","            \"time\": rag_time,\n","            \"correct\": \"Y\" if rag_correct else \"N\"\n","        })\n","        results.append({\n","            \"question\": question,\n","            \"method\": \"Fine-Tune\",\n","            \"answer\": ft_answer,\n","            \"confidence\": ft_confidence,\n","            \"time\": ft_time,\n","            \"correct\": \"Y\" if ft_correct else \"N\"\n","        })\n","    return results\n","\n","# Run Evaluation\n","ft_model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_model\")\n","ft_tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n","evaluation_results = evaluate_systems(rag_generate, ft_model, ft_tokenizer, test_questions, chunks, faiss_index, bm25, chunk_ids, emb_model)\n","\n","# 4.3 Results Table\n","import pandas as pd\n","df = pd.DataFrame(evaluation_results)\n","print(df.to_markdown())\n","\n","# 4.4 Analysis\n","rag_avg_time = df[df['method'] == 'RAG']['time'].mean()\n","ft_avg_time = df[df['method'] == 'Fine-Tune']['time'].mean()\n","rag_accuracy = len(df[(df['method'] == 'RAG') & (df['correct'] == 'Y')]) / len(df[df['method'] == 'RAG'])\n","ft_accuracy = len(df[(df['method'] == 'Fine-Tune') & (df['correct'] == 'Y')]) / len(df[df['method'] == 'Fine-Tune'])\n","print(f\"RAG Average Time: {rag_avg_time:.2f} seconds, Accuracy: {rag_accuracy:.2%}\")\n","print(f\"Fine-Tune Average Time: {ft_avg_time:.2f} seconds, Accuracy: {ft_accuracy:.2%}\")\n","print(\"\"\"\n","**Analysis**:\n","- **RAG Strengths**: Combines sparse and dense retrieval for high recall and precision. Effective for factual grounding, especially for numerical queries.\n","- **Fine-Tuning Strengths**: Faster inference, more fluent responses, but may overfit to training data.\n","- **Robustness**: RAG handles irrelevant queries better due to retrieval filtering; fine-tuned model may generate irrelevant responses.\n","- **Trade-offs**: RAG requires more computational resources for retrieval; fine-tuning needs significant training time but is efficient at inference.\n","\"\"\")"],"outputs":[],"id":"RoRmLSMFKQqe","execution_count":null},{"cell_type":"markdown","metadata":{"id":"bSH026GBKQqf"},"source":["## 5. Streamlit Interface"],"id":"bSH026GBKQqf"},{"cell_type":"code","metadata":{"id":"NxsDC7iAKQqf"},"source":["def main():\n","    st.set_page_config(layout=\"wide\")\n","    st.title(\"Infosys Financial QA System ðŸ“ˆ (RAG vs Fine-Tuned)\")\n","    st.write(\"Ask questions about Infosys's financial statements (2023-2024). Switch between RAG and Fine-Tuned modes.\")\n","\n","    @st.cache_resource(show_spinner=False)\n","    def load_resources():\n","        try:\n","            emb_model = SentenceTransformer(RetrievalConfig.EMB_MODEL_NAME)\n","            chunks = json.load(open(\"data/chunks/all_sentence_chunks.json\", 'r', encoding='utf-8'))\n","            faiss_index = faiss.read_index(\"data/retrieval/faiss_index.bin\")\n","            with open(\"data/retrieval/faiss_index_ids.pkl\", 'rb') as f:\n","                chunk_ids = pickle.load(f)\n","            with open(\"data/retrieval/bm25_index.pkl\", 'rb') as f:\n","                bm25 = pickle.load(f)\n","            ft_model = AutoModelForCausalLM.from_pretrained(\"./fine_tuned_model\")\n","            ft_tokenizer = AutoTokenizer.from_pretrained(\"./fine_tuned_model\")\n","            return emb_model, chunks, faiss_index, chunk_ids, bm25, ft_model, ft_tokenizer\n","        except Exception as e:\n","            st.error(f\"Resource loading error: {e}\")\n","            return None, None, None, None, None, None, None\n","\n","    resources = load_resources()\n","    if not all(resources):\n","        st.error(\"Failed to load all resources.\")\n","        return\n","\n","    emb_model, chunks, faiss_index, chunk_ids, bm25, ft_model, ft_tokenizer = resources\n","    mode = st.selectbox(\"Select Mode\", [\"RAG\", \"Fine-Tuned\"])\n","    query = st.text_input(\"Enter your financial query:\", \"What were the total assets in 2023?\")\n","\n","    if mode == \"RAG\":\n","        col1, col2, col3 = st.columns([1,1,1])\n","        with col1:\n","            alpha = st.slider(\"Dense weight (Î±)\", 0.0, 1.0, RetrievalConfig.DENSE_WEIGHT, 0.05)\n","        with col2:\n","            beta = st.slider(\"Sparse weight (Î²)\", 0.0, 1.0, RetrievalConfig.SPARSE_WEIGHT, 0.05)\n","        with col3:\n","            topk = st.slider(\"Final Top-K\", 3, 15, RetrievalConfig.FINAL_TOP_K, 1)\n","        RetrievalConfig.DENSE_WEIGHT = alpha\n","        RetrievalConfig.SPARSE_WEIGHT = beta\n","        RetrievalConfig.FINAL_TOP_K = topk\n","\n","    if st.button(\"Submit Query\"):\n","        if not query.strip():\n","            st.warning(\"Please enter a query.\")\n","            return\n","        start = time.time()\n","        if mode == \"RAG\":\n","            if not validate_query(query):\n","                st.error(\"Invalid query. Please ask a financial-related question.\")\n","                return\n","            with st.spinner(\"Retrieving relevant documents...\"):\n","                retrieved_chunks, scores = hybrid_retrieval(query, chunks, faiss_index, bm25, chunk_ids, emb_model)\n","            with st.spinner(\"Generating answer...\"):\n","                answer = rag_generate(query, retrieved_chunks, RetrievalConfig)\n","            confidence = max(scores) if scores else 0.0\n","            method = \"RAG (Hybrid Search)\"\n","        else:\n","            with st.spinner(\"Generating answer...\"):\n","                ft_generator = pipeline('text-generation', model=ft_model, tokenizer=ft_tokenizer, device=-1)\n","                prompt = f\"Question: {query}\\nAnswer:\"\n","                response = ft_generator(prompt, max_new_tokens=50, do_sample=False)[0]['generated_text']\n","                answer = response.replace(prompt, \"\").strip()\n","                confidence = 1.0 if validate_output(answer) else 0.5\n","                method = \"Fine-Tuned (Retrieval-Augmented)\"\n","        elapsed = time.time() - start\n","        st.subheader(\"Answer\")\n","        st.markdown(f\"**{answer}** (Confidence: {confidence:.2f}, Time: {elapsed:.2f} sec, Method: {method})\")\n","        if mode == \"RAG\":\n","            with st.expander(\"Show Retrieval Details\"):\n","                st.write(f\"**Response Time**: {elapsed:.2f} sec\")\n","                st.write(f\"**Merged Context Blocks**: {len(retrieved_chunks)}\")\n","                for i, ch in enumerate(retrieved_chunks, 1):\n","                    src = ch['metadata'].get('file_path', 'unknown')\n","                    st.info(f\"**[{i}] Source**: {src}\\n\\n**Text**: {ch['text'][:1200]}{'...' if len(ch['text'])>1200 else ''}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"outputs":[],"id":"NxsDC7iAKQqf","execution_count":null},{"cell_type":"markdown","metadata":{"id":"EwFq378WKQqf"},"source":["## Submission Notes\n","\n","- **ZIP File**: `Group_X_RAG_vs_FT.zip` contains this notebook and a PDF report with screenshots, comparison table, and analysis.\n","- **Hosted App**: Deployed on Streamlit Cloud (link to be provided).\n","- **Dependencies**: Ensure `PyMuPDF`, `pdfplumber`, `pytesseract`, `pdf2image`, `sentence-transformers`, `faiss`, `rank-bm25`, `nltk`, `streamlit`, `transformers`, `datasets` are installed.\n","- **Advanced Techniques**:\n","  - **RAG**: Hybrid Search (BM25 + Dense Retrieval) for balanced recall and precision.\n","  - **Fine-Tuning**: Retrieval-Augmented Fine-Tuning to enhance knowledge grounding.\n","- **Guardrails**:\n","  - **RAG**: Input-side validation to filter non-financial queries.\n","  - **Fine-Tuning**: Output-side validation to detect hallucinated responses."],"id":"EwFq378WKQqf"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}